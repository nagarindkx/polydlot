{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Square Video Prediction\n",
    "\n",
    "This is the third toy example from Jason Brownlee's [Long Short Term Memory Networks with Python](https://machinelearningmastery.com/lstms-with-python/). It illustrates using a CNN LSTM, ie, an LSTM with input from CNN. Per section 8.2 of the book:\n",
    "\n",
    "> The moving square video prediction problem is contrived to demonstrate the CNN LSTM. The\n",
    "problem involves the generation of a sequence of frames. In each image a line is drawn from left to right or right to left. Each frame shows the extension of the line by one pixel. The task is for the model to classify whether the line moved left or right in the sequence of frames. Technically, the problem is a sequence classification problem framed with a many-to-one prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\"\n",
    "MODEL_FILE = os.path.join(DATA_DIR, \"torch-08-moving-square-{:d}.model\")\n",
    "\n",
    "TRAINING_SIZE = 5000\n",
    "VALIDATION_SIZE = 100\n",
    "TEST_SIZE = 500\n",
    "\n",
    "SEQUENCE_LENGTH = 50\n",
    "FRAME_SIZE = 50\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "Our data is going to be batches of sequences of images. Each image will need to be in channel-first format, since Pytorch only supports that format. So our output data will be in the (batch_size, sequence_length, num_channels, height, width) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAABkCAYAAADT76S7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e922690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def next_frame(frame, x, y, move_right, upd_int):\n",
    "    frame_size = frame.shape[0]\n",
    "    if x is None and y is None:\n",
    "        x = 0 if (move_right == 1) else (frame_size - 1)\n",
    "        y = np.random.randint(0, frame_size, 1)[0]\n",
    "    else:\n",
    "        if y == 0:\n",
    "            y = np.random.randint(y, y + 1, 1)[0]\n",
    "        elif y == frame_size - 1:\n",
    "            y = np.random.randint(y - 1, y, 1)[0]\n",
    "        else:\n",
    "            y = np.random.randint(y - 1, y + 1, 1)[0]\n",
    "        if move_right:\n",
    "            x = x + 1\n",
    "        else:\n",
    "            x = x - 1\n",
    "    new_frame = frame.copy()\n",
    "    new_frame[y, x] = upd_int\n",
    "    return new_frame, x, y\n",
    "\n",
    "row, col = None, None\n",
    "frame = np.ones((5, 5))\n",
    "move_right = 1 if np.random.random() < 0.5 else 0\n",
    "for i in range(5):\n",
    "    frame, col, row = next_frame(frame, col, row, move_right, 0)\n",
    "    plt.subplot(1, 5, (i+1))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title((col, row, \"R\" if (move_right==1) else \"L\"))\n",
    "    plt.imshow(frame, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50, 1, 50, 50) (10,)\n"
     ]
    }
   ],
   "source": [
    "def generate_data(frame_size, sequence_length, num_samples):\n",
    "    assert(frame_size == sequence_length)\n",
    "    xs, ys = [], []\n",
    "    for bid in range(num_samples):\n",
    "        frame_seq = []\n",
    "        row, col = None, None\n",
    "        frame = np.ones((frame_size, frame_size))\n",
    "        move_right = 1 if np.random.random() < 0.5 else 0\n",
    "        for sid in range(sequence_length):\n",
    "            frm, col, row = next_frame(frame, col, row, move_right, 0)\n",
    "            frm = frm.reshape((1, frame_size, frame_size))\n",
    "            frame_seq.append(frm)\n",
    "        xs.append(np.array(frame_seq))\n",
    "        ys.append(move_right)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "X, y = generate_data(FRAME_SIZE, SEQUENCE_LENGTH, 10)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 50, 1, 50, 50) (5000,) (100, 50, 1, 50, 50) (100,) (500, 50, 1, 50, 50) (500,)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, ytrain = generate_data(FRAME_SIZE, SEQUENCE_LENGTH, TRAINING_SIZE)\n",
    "Xval, yval = generate_data(FRAME_SIZE, SEQUENCE_LENGTH, VALIDATION_SIZE)\n",
    "Xtest, ytest = generate_data(FRAME_SIZE, SEQUENCE_LENGTH, TEST_SIZE)\n",
    "print(Xtrain.shape, ytrain.shape, Xval.shape, yval.shape, Xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network\n",
    "\n",
    "We want to build a CNN-LSTM network. Each image in the sequence will be fed to a CNN which will learn to produce a feature vector for the image. The sequence of vectors will be fed into an LSTM and the LSTM will learn to generate a context vector that will be then fed into a FCN that will predict if the square is moving left or right.\n",
    "\n",
    "<img src=\"08-network-design.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN (\n",
      "  (conv1): Conv2d(1, 2, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU ()\n",
      ")\n",
      "--- size debugging ---\n",
      "torch.Size([32, 1250])\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_height, input_width, input_channels, \n",
    "                 output_channels, \n",
    "                 conv_kernel_size, conv_stride, conv_padding,\n",
    "                 pool_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, output_channels, \n",
    "                               kernel_size=conv_kernel_size, \n",
    "                               stride=conv_stride, \n",
    "                               padding=conv_padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.output_height = input_height // pool_size\n",
    "        self.output_width = input_width // pool_size\n",
    "        self.output_channels = output_channels\n",
    "        self.pool_size = pool_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = F.max_pool2d(x, self.pool_size)\n",
    "        x = x.view(x.size(0), self.output_channels * self.output_height * self.output_width)\n",
    "        return x\n",
    "\n",
    "cnn = CNN(FRAME_SIZE, FRAME_SIZE, 1, 2, 2, 1, 1, 2)\n",
    "print(cnn)\n",
    "\n",
    "# size debugging\n",
    "print(\"--- size debugging ---\")\n",
    "inp = Variable(torch.randn(BATCH_SIZE, 1, FRAME_SIZE, FRAME_SIZE))\n",
    "out = cnn(inp)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNLSTM (\n",
      "  (cnn): CNN (\n",
      "    (conv1): Conv2d(1, 2, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (relu1): ReLU ()\n",
      "  )\n",
      "  (lstm): LSTM(1250, 50, batch_first=True)\n",
      "  (fc): Linear (50 -> 2)\n",
      "  (softmax): Softmax ()\n",
      ")\n",
      "--- size debugging ---\n",
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "class CNNLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_size, input_channels, output_channels, \n",
    "                 conv_kernel_size, conv_stride, conv_padding, pool_size, \n",
    "                 seq_length, hidden_size, num_layers, output_size):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        # capture variables\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_length = seq_length\n",
    "        self.image_size = image_size\n",
    "        self.output_channels = output_channels\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm_input_size = output_channels * (image_size // pool_size) ** 2\n",
    "        # define network layers\n",
    "        self.cnn = CNN(image_size, image_size, input_channels, output_channels, \n",
    "                       conv_kernel_size, conv_stride, conv_padding, pool_size)\n",
    "        self.lstm = nn.LSTM(self.lstm_input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if torch.cuda.is_available():\n",
    "            h0 = (Variable(torch.randn(self.num_layers, x.size(0), self.hidden_size).cuda()),\n",
    "                  Variable(torch.randn(self.num_layers, x.size(0), self.hidden_size).cuda()))\n",
    "        else:\n",
    "            h0 = (Variable(torch.randn(self.num_layers, x.size(0), self.hidden_size)),\n",
    "                  Variable(torch.randn(self.num_layers, x.size(0), self.hidden_size)))\n",
    "        \n",
    "        cnn_out = []\n",
    "        for i in range(self.seq_length):\n",
    "            cnn_out.append(self.cnn(x[:, i, :, :, :]))\n",
    "        x = torch.cat(cnn_out, dim=1).view(-1, self.seq_length, self.lstm_input_size)\n",
    "        x, h0 = self.lstm(x, h0)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        x = self.softmax(x)\n",
    "        return x        \n",
    "\n",
    "model = CNNLSTM(FRAME_SIZE, 1, 2, 2, 1, 1, 2, SEQUENCE_LENGTH, 50, 1, 2)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "print(model)\n",
    "\n",
    "# size debugging\n",
    "print(\"--- size debugging ---\")\n",
    "inp = Variable(torch.randn(BATCH_SIZE, SEQUENCE_LENGTH, 1, FRAME_SIZE, FRAME_SIZE))\n",
    "out = model(inp)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Network\n",
    "\n",
    "Training on GPU is probably preferable for this example, takes a long time on CPU. During some runs, the training and validation accuracies get stuck, possibly because of bad initializations, the fix appears to be to just retry the training until it results in good training and validation accuracies and use the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/5: loss=0.649, acc=0.640, val_loss=0.409, val_acc=0.958\n",
      "Epoch  2/5: loss=0.357, acc=0.966, val_loss=0.324, val_acc=0.990\n",
      "Epoch  3/5: loss=0.344, acc=0.970, val_loss=0.328, val_acc=0.990\n",
      "Epoch  4/5: loss=0.340, acc=0.974, val_loss=0.315, val_acc=1.000\n",
      "Epoch  5/5: loss=0.339, acc=0.975, val_loss=0.320, val_acc=1.000\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(pred_var, true_var):\n",
    "    if torch.cuda.is_available():\n",
    "        ypred = pred_var.cpu().data.numpy()\n",
    "        ytrue = true_var.cpu().data.numpy()\n",
    "    else:\n",
    "        ypred = pred_var.data.numpy()\n",
    "        ytrue = true_var.data.numpy()\n",
    "    return accuracy_score(ypred, ytrue)\n",
    "    \n",
    "history = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    num_batches = Xtrain.shape[0] // BATCH_SIZE\n",
    "    \n",
    "    shuffled_indices = np.random.permutation(np.arange(Xtrain.shape[0]))\n",
    "    train_loss, train_acc = 0., 0.\n",
    "    for bid in range(num_batches):\n",
    "        Xbatch_data = Xtrain[shuffled_indices[bid * BATCH_SIZE : (bid+1) * BATCH_SIZE]]\n",
    "        ybatch_data = ytrain[shuffled_indices[bid * BATCH_SIZE : (bid+1) * BATCH_SIZE]]\n",
    "        Xbatch = Variable(torch.from_numpy(Xbatch_data).float())\n",
    "        ybatch = Variable(torch.from_numpy(ybatch_data).long())\n",
    "        if torch.cuda.is_available():\n",
    "            Xbatch = Xbatch.cuda()\n",
    "            ybatch = ybatch.cuda()\n",
    "            \n",
    "        # initialize gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward\n",
    "        Ybatch_ = model(Xbatch)\n",
    "        loss = loss_fn(Ybatch_, ybatch)\n",
    "        \n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        _, ybatch_ = Ybatch_.max(1)\n",
    "        train_acc += compute_accuracy(ybatch_, ybatch)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    # compute training loss and accuracy\n",
    "    train_loss /= num_batches\n",
    "    train_acc /= num_batches\n",
    "    \n",
    "    # compute validation loss and accuracy\n",
    "    val_loss, val_acc = 0., 0.\n",
    "    num_val_batches = Xval.shape[0] // BATCH_SIZE\n",
    "    for bid in range(num_val_batches):\n",
    "        # data\n",
    "        Xbatch_data = Xval[bid * BATCH_SIZE : (bid + 1) * BATCH_SIZE]\n",
    "        ybatch_data = yval[bid * BATCH_SIZE : (bid + 1) * BATCH_SIZE]\n",
    "        Xbatch = Variable(torch.from_numpy(Xbatch_data).float())\n",
    "        ybatch = Variable(torch.from_numpy(ybatch_data).long())\n",
    "        if torch.cuda.is_available():\n",
    "            Xbatch = Xbatch.cuda()\n",
    "            ybatch = ybatch.cuda()\n",
    "\n",
    "        Ybatch_ = model(Xbatch)\n",
    "        loss = loss_fn(Ybatch_, ybatch)\n",
    "        val_loss += loss.data[0]\n",
    "\n",
    "        _, ybatch_ = Ybatch_.max(1)\n",
    "        val_acc += compute_accuracy(ybatch_, ybatch)\n",
    "        \n",
    "    val_loss /= num_val_batches\n",
    "    val_acc /= num_val_batches\n",
    "    \n",
    "    torch.save(model.state_dict(), MODEL_FILE.format(epoch+1))\n",
    "    print(\"Epoch {:2d}/{:d}: loss={:.3f}, acc={:.3f}, val_loss={:.3f}, val_acc={:.3f}\"\n",
    "          .format((epoch+1), NUM_EPOCHS, train_loss, train_acc, val_loss, val_acc))\n",
    "    \n",
    "    history.append((train_loss, val_loss, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt8VNW5//HPQwyECApyVaIGrZcAIgIi3mmpFfFKBYF6\nq/aU6pHj9adS21p79LR6aj3WilqsHLVeqAUvaLF4rCDeNVhEEBRUlIBKwIKoIASe3x9rIkOckAmZ\nmb1n8n2/XvPKzN579nyz0Hmy9157LXN3RERE4qZF1AFERERSUYESEZFYUoESEZFYUoESEZFYUoES\nEZFYUoESEZFYUoESEZFYUoESScHMZprZv8ysVdRZRJorFSiROsysHDgScOCkHH7uDrn6LJF8oAIl\n8k1nAS8DdwNn1y40s9Zm9jsz+8DM1pjZ82bWOrHuCDN70cxWm9lSM/thYvlMM/u3pH380MyeT3rt\nZnaBmS0CFiWW/T6xj8/MbLaZHZm0fZGZXWVm75rZ2sT63c1svJn9LvmXMLOpZnZJNhpIJBdUoES+\n6Szg/sTjWDPrklh+I9APOAzYBbgC2GxmewJPAn8AOgF9gDmN+LxTgEOAHonXryX2sQvwAPBXMytJ\nrLsUGA0MBXYCzgW+BO4BRptZCwAz6wh8N/F+kbykAiWSxMyOAPYEHnL32cC7wA8SX/znAhe5+zJ3\n3+TuL7r7V8APgKfd/UF33+juq9y9MQXqN+7+qbuvA3D3+xL7qHH33wGtgP0S2/4b8HN3f9uDNxLb\nvgqsAQYnthsFzHT3T5rYJCKRUYES2drZwFPuvjLx+oHEso5ACaFg1bV7PcvTtTT5hZn9PzNbkDiN\nuBrYOfH5DX3WPcAZiednAH9uQiaRyOmirEhC4nrSaUCRmX2cWNwKaAfsCqwH9gbeqPPWpcCAenb7\nBVCa9Lprim2+nlIgcb3pCsKR0Hx332xm/wIs6bP2Bual2M99wDwzOxCoAB6tJ5NIXtARlMgWpwCb\nCNeC+iQeFcBzhOtSE4GbzGy3RGeFQxPd0O8Hvmtmp5nZDmbWwcz6JPY5B/i+mZWa2beAHzWQoS1Q\nA1QDO5jZ1YRrTbX+BFxrZvtY0NvMOgC4exXh+tWfgSm1pwxF8pUKlMgWZwP/6+4fuvvHtQ/gVuB0\nYBzwJqEIfArcALRw9w8JnRYuSyyfAxyY2Of/ABuATwin4O5vIMN04O/AO8AHhKO25FOANwEPAU8B\nnwF3Aa2T1t8DHIBO70kBME1YKFI4zOwowqm+PV3/c0ue0xGUSIEws2LgIuBPKk5SCFSgRAqAmVUA\nqwmdOW6OOI5IRugUn4iIxJKOoEREJJYiuw+qY8eOXl5eHtXHi4hIRGbPnr3S3Ts1tF1kBaq8vJzK\nysqoPl5ERCJiZh+ks12Dp/jMbKKZrTCzVHeuk7hZ8BYzW2xmc82sb2PDioiI1JXOEdTdhBsV761n\n/XHAPonHIcDtiZ8iIjlVUwMbNkSdorC1bAk75OjcW4Mf4+6zEhO41edk4N7EfRcvm1k7M9vV3T/K\nUEYRibGaGli/Hr76KjzSeZ7udo19/+bNUbdG4fvjH2HMmNx8VibqYDe2HoqlKrHsGwXKzMYAYwD2\n2GOPDHy0SPO0PUUhWwUiU0WhZUsoKYFWrbY8kl+XlECbNqmXJz8vLgazhj9Pts+A+oZFzoKcdpJw\n9wnABID+/fvrBqwYqKmBVatgxYqtH9XV4QtIsqOmpmnFIltFIVWBSKcobOv96Txv2VJFRb4pEwVq\nGWGOmlpliWUSAXf47LNvFpz6HqtWhffUVVQUvjgkO1q02PIlneqLe3uLQmMKhIqCxF0mCtRUYKyZ\nTSJ0jlij60+ZtX59esWmujr8rO8icfv20KkTdO4M++8PRx0Vnqd6tG8fvkRFRKLSYIEysweBQUBH\nM6sCfgkUA7j7HcA0wlQDi4EvgXOyFbZQJJ9Wqy0q23qsXZt6PyUl0KVLKCi77QZ9+tRfcDp2DH8x\ni4jki3R68Y1uYL0DF2QsUR7K5Gm12iOczp3Dxcj6Ck7nzrDjjjpF0yy4h4tOmzaFn8nP474sqgzu\nWx61bVj30djlmdxXLj4jG3khp934NOV7Peo7rVbfEU99p9XatdtSUJrFabXaL4nkR03NN5fV90h3\n23zZ57a2TfcLt1CZhf/gi4rCz+TnTVnWokXYd/Kj9vPqW173PfVtn86+mro8rvuqXd43d2MxNJsC\ntWlT6t5qTTmttuuucOCBWwpM8tFP7eu8PK22di385CdQWdn4L918UfuFVvvYYYetX2/rUd+2LVum\nv23tI9WXaya+pKNa1pj36PBfGpC3Baoxp9Wqq2HlytSn1Vq00Gm1rXz8MRx/PLzxBgwbFrp8NfZL\nd3u2zcY+69tWX44ieSFvC9TSpbDnnqnXNXRaLbkg7bJLAZxWy5RFi+DYY+GTT+Cxx0KhEhGJSN4W\nqC5d4MYbU/dWa9Uq6nR56NVXtxSkGTNye7u4iEgKeVugWrWCyy6LOkWB+Nvf4LTTQtWfPh322Sfq\nRCIimlG32Zs4EU4+OZwLfeklFScRiQ0VqObKHa69Fn70Ixg8GGbODEdQIiIxkben+KQJNm2CCy4I\nN9ydeSb86U952h9eRAqZjqCamy+/hFNPDcVp3Di45x4VJxGJJR1BNSerVsGJJ8LLL8Mf/gBjx0ad\nSESkXipQzcUHH8CQIfD++/DQQzB8eNSJRES2SQWqOXjjDTjuuHB676mnwp3LIiIxp2tQhe6ZZ0JB\nKiqC559XcRKRvJFWgTKzIWb2tpktNrNxKda3N7NHzGyumb1qZr0yH1UabdKkcFpv993hxRehl/5Z\nRCR/NFigzKwIGA8cB/QARptZjzqbXQXMcffewFnA7zMdVBrppptg9Gg49FB47rlQpERE8kg6R1AD\ngMXu/p67bwAmASfX2aYH8AyAuy8Eys1Md31GYfPmMAbUZZeF7uTTp4eJpkRE8kw6BaobsDTpdVVi\nWbI3gO8DmNkAYE+gLBMBpRG++grOOCMcPY0dC3/5S5jASkQkD2Wqk8T1QDszmwP8B/BP4Buz15nZ\nGDOrNLPK6urqDH20ALBmDQwdCg8+CNdfD7fcEjpGiIjkqXS6mS8Dki9glCWWfc3dPwPOATAzA94H\n3qu7I3efAEwA6N+/f4rpA2W7LF8eupG/9Rbce28YvkhEJM+lU6BeA/Yxs+6EwjQK+EHyBmbWDvgy\ncY3q34BZiaIl2bZwYeipt3IlPPFEmHBQRKQANFig3L3GzMYC04EiYKK7zzez8xLr7wAqgHvMzIH5\nwI+ymFlqvfhiGLpohx3g2WehX7+oE4mIZExaI0m4+zRgWp1ldyQ9fwnYN7PRZJumToWRI6GsLPTU\n22uvqBOJiGSURpLIR3/8IwwbBgccEI6iVJxEpACpQOUTd7j6ajjvvHDdacYM6NQp6lQiIlmhwWLz\nRU1NKEx33QXnnhuOonbQP5+IFC4dQeWDL76AU04JxennPw8z4Ko4iUiB07dc3FVXwwknQGUl3H57\nOIoSEWkGVKDi7L33wrWmpUthypRwFCUi0kyoQMXV66+HoYs2bICnn4bDD486kYhITukaVBw99RQc\nfTS0agUvvKDiJCLNkgpU3Nx3Hxx/fLi36aWXoKIi6kQiIpFQgYoLd/jv/w4DvR55JMyaBbvtFnUq\nEZHIqEDFwaZNcPHFcOWVMGoUPPkk7Lxz1KlERCKlAhW19etDUbrlFrj0Urj//nDtSUSkmVMvviit\nXh26jj/7LNx4Y5imXUREABWo6FRVhUkG334bHngARo+OOpGISKyoQEVh/vxwA+6aNeF60+DBUScS\nEYmdtK5BmdkQM3vbzBab2bgU63c2s8fN7A0zm29m52Q+aoF47jk44ogw+OusWSpOIiL1aLBAmVkR\nMB44DugBjDazHnU2uwB4y90PBAYBvzOzlhnOmv8efhiOOQa6dAn3OPXpE3UiEZHYSucIagCw2N3f\nc/cNwCTg5DrbONDWzAxoA3wK1GQ0ab4bPx6GD4e+fcPoEOXlUScSEYm1dApUN2Bp0uuqxLJktwIV\nwHLgTeAid9+ckYT5zh2uugrGjoUTTwzj6nXoEHUqEZHYy9R9UMcCc4DdgD7ArWa2U92NzGyMmVWa\nWWV1dXWGPjrGNm6EH/4QfvMbGDMmjEheWhp1KhGRvJBOgVoG7J70uiyxLNk5wMMeLAbeB/avuyN3\nn+Du/d29f6dCn6r888/DEdO998J//ifccYcmGRQRaYR0CtRrwD5m1j3R8WEUMLXONh8CgwHMrAuw\nH/BeJoPmlU8+gUGDwum8O++EX/wCzKJOJSKSVxr8k97da8xsLDAdKAImuvt8Mzsvsf4O4FrgbjN7\nEzDgSndfmcXc8bV4MRx7LHz0ETz6aJgNV0REGi2tc07uPg2YVmfZHUnPlwPfy2y0PPTaa2GqjM2b\nYcYMOOSQqBOJSMxs3LiRqqoq1q9fH3WUrCspKaGsrIzi4uLter8uimTKk0+GbuRdusDf/w777ht1\nIhGJoaqqKtq2bUt5eTlWwKf+3Z1Vq1ZRVVVF9+7dt2sfGs08E+6+O3SI2G8/ePFFFScRqdf69evp\n0KFDQRcnADOjQ4cOTTpSVIFqCnf4r/+Cc86B73wnjEretWvUqUQk5gq9ONVq6u+pU3zba9Mm+I//\ngNtvhzPOgLvugpYa3UlEJFN0BLU91q0L15tuvx2uuALuuUfFSUTywurVq7ntttsa/b6hQ4eyevXq\nLCSqnwpUY336aRjw9bHH4Pe/hxtugBZqRhHJD/UVqJqabQ+fOm3aNNq1a5etWCnpFF9jfPhhmMfp\n3XfhL3+BESOiTiQi0ijjxo3j3XffpU+fPhQXF1NSUkL79u1ZuHAh77zzDqeccgpLly5l/fr1XHTR\nRYwZMwaA8vJyKisr+fzzzznuuOM44ogjePHFF+nWrRuPPfYYrVu3znhWFah0zZ0bZsD94gt46ik4\n+uioE4lIvrv4YpgzJ7P77NMHbr653tXXX3898+bNY86cOcycOZPjjz+eefPmfd0VfOLEieyyyy6s\nW7eOgw8+mFNPPZUOdQa4XrRoEQ8++CB33nknp512GlOmTOGMM87I7O+BTvGlZ+ZMOPLIMFzRc8+p\nOIlIwRgwYMBW9yndcsstHHjggQwcOJClS5eyaNGib7yne/fu9EnMZ9evXz+WLFmSlWw6gmrIX/4C\nZ50F3/pWuAF3990bfo+ISDq2caSTKzvuuOPXz2fOnMnTTz/NSy+9RGlpKYMGDUp5H1OrVq2+fl5U\nVMS6deuykk1HUNty880walQYsuj551WcRCTvtW3blrVr16Zct2bNGtq3b09paSkLFy7k5ZdfznG6\nrekIKpXNm+HKK+HGG+H734f774eSkqhTiYg0WYcOHTj88MPp1asXrVu3pkuXLl+vGzJkCHfccQcV\nFRXst99+DBw4MMKkYO4eyQf379/fKysrI/nsbdqwIYwM8cADcMEFoSt5UVHUqUSkQCxYsICKioqo\nY+RMqt/XzGa7e/+G3qsjqGSffQannhrmcfr1r2HcOM3jJCISERWoWh99BEOHwrx5YfDXs8+OOpGI\nSLOWVicJMxtiZm+b2WIzG5di/eVmNifxmGdmm8xsl8zHzZK334bDDoNFi+Dxx1WcRERioMECZWZF\nwHjgOKAHMNrMeiRv4+6/dfc+7t4H+CnwrLt/mo3AGffyy3D44fDll+F+pyFDok4kIiKkdwQ1AFjs\n7u+5+wZgEnDyNrYfDTyYiXBZ9/jjYZqMdu3CPE79G7xmJyIiOZJOgeoGLE16XZVY9g1mVgoMAaY0\nPVqW3XknnHIK9OwZitPee0edSEREkmT6Rt0TgRfqO71nZmPMrNLMKqurqzP80Wlyh2uugTFj4Nhj\nYcYM6Nw5miwiIjHXpk0bAJYvX87w4cNTbjNo0CCycdtQOgVqGZA8hEJZYlkqo9jG6T13n+Du/d29\nf6dOndJPmSk1NfCTn8CvfgU//GGYMiPR+CIiUr/ddtuNyZMn5/Qz0ylQrwH7mFl3M2tJKEJT625k\nZjsDRwOPZTZihnz5ZRgV4s474Wc/g4kTobg46lQiIjk1btw4xo8f//Xra665huuuu47BgwfTt29f\nDjjgAB577Jtf40uWLKFXr14ArFu3jlGjRlFRUcGwYcOyNhZfg/dBuXuNmY0FpgNFwER3n29m5yXW\n35HYdBjwlLt/kZWkTbFyJZx4IrzyCtx2G5x/ftSJRESimG2DkSNHcvHFF3PBBRcA8NBDDzF9+nQu\nvPBCdtppJ1auXMnAgQM56aSTsHoGKrj99tspLS1lwYIFzJ07l759+2b2l0hI60Zdd58GTKuz7I46\nr+8G7s5UsIx5//3QdfzDD2HKFBg2LOpEIiKROeigg1ixYgXLly+nurqa9u3b07VrVy655BJmzZpF\nixYtWLZsGZ988gldu3ZNuY9Zs2Zx4YUXAtC7d2969+6dlayFPZLEP/8ZRof46qswfNHhh0edSETk\na1HNtjFixAgmT57Mxx9/zMiRI7n//vuprq5m9uzZFBcXU15ennKajVwr3Ok2nn46TCxYXBymylBx\nEhEBwmm+SZMmMXnyZEaMGMGaNWvo3LkzxcXFzJgxgw8++GCb7z/qqKN44IEHAJg3bx5z587NSs7C\nLFD33x+mZy8vh5degh49GnyLiEhz0bNnT9auXUu3bt3YddddOf3006msrOSAAw7g3nvvZf/999/m\n+88//3w+//xzKioquPrqq+nXr19WchbWdBvu8LvfweWXw6BB8MgjYZQIEZGY0HQb6U+3UThHUJs3\nw6WXhuJ02mlhenYVJxGRvFUYBeqrr2D06HDF8eKL4cEHoVWrqFOJiEgT5H8vvtWrQ9fxmTPht7+F\nyy7TJIMiEmvuXu89RoWkqZeQ8rtALVsWOkMsXAj33Qennx51IhGRbSopKWHVqlV06NChoIuUu7Nq\n1SpKSkq2ex/5W6Deey90hFi9GqZNg+9+N+pEIiINKisro6qqisgGzM6hkpISysrKtvv9+VugunYN\n8zddfXUY20NEJA8UFxfTvXv3qGPkhfwtUKWl8PDDUacQEZEsKYxefCIiUnBUoEREJJYiG0nCzKqB\nbQ/4lJ6OwMoM7CcX8ikrKG825VNWyK+8+ZQVmmfePd29wVlrIytQmWJmlekMmREH+ZQVlDeb8ikr\n5FfefMoKyrstOsUnIiKxpAIlIiKxVAgFakLUARohn7KC8mZTPmWF/MqbT1lBeeuV99egRESkMBXC\nEZSIiBQgFSgREYmlvChQZjbEzN42s8VmNi7FejOzWxLr55pZ3yhyJuVpKO8gM1tjZnMSj6ujyJnI\nMtHMVpjZvHrWx61tG8obp7bd3cxmmNlbZjbfzC5KsU1s2jfNvLFoXzMrMbNXzeyNRNZfpdgmTm2b\nTt5YtG1SniIz+6eZPZFiXW7a1t1j/QCKgHeBvYCWwBtAjzrbDAWeBAwYCLwS87yDgCeibttElqOA\nvsC8etbHpm3TzBuntt0V6Jt43hZ4J+b/7aaTNxbtm2ivNonnxcArwMAYt206eWPRtkl5LgUeSJUp\nV22bD0dQA4DF7v6eu28AJgEn19nmZOBeD14G2pnZrrkOmpBO3thw91nAp9vYJE5tm07e2HD3j9z9\n9cTztcACoFudzWLTvmnmjYVEe32eeFmceNTt8RWntk0nb2yYWRlwPPCnejbJSdvmQ4HqBixNel3F\nN/+nSWebXEk3y2GJQ+MnzaxnbqJtlzi1bbpi17ZmVg4cRPjLOVks23cbeSEm7Zs4BTUHWAH8n7vH\num3TyAsxaVvgZuAKYHM963PStvlQoArR68Ae7t4b+APwaMR5Ckns2tbM2gBTgIvd/bOo8zSkgbyx\naV933+TufYAyYICZ9YoqSzrSyBuLtjWzE4AV7j47is9Plg8Fahmwe9LrssSyxm6TKw1mcffPag/3\n3X0aUGxmHXMXsVHi1LYNilvbmlkx4cv+fndPNYFZrNq3obxxa99EjtXADGBInVWxatta9eWNUdse\nDpxkZksIlyi+Y2b31dkmJ22bDwXqNWAfM+tuZi2BUcDUOttMBc5K9CwZCKxx949yHTShwbxm1tXM\nLPF8AOHfYVXOk6YnTm3boDi1bSLHXcACd7+pns1i077p5I1L+5pZJzNrl3jeGjgGWFhnszi1bYN5\n49K27v5Tdy9z93LC99cz7n5Gnc1y0raxn1HX3WvMbCwwndBDbqK7zzez8xLr7wCmEXqVLAa+BM6J\ned7hwPlmVgOsA0Z5omtMrpnZg4TeQx3NrAr4JeECbuzaFtLKG5u2JfwleibwZuLaA8BVwB4Qy/ZN\nJ29c2ndX4B4zKyJ8kT/k7k/E9XuB9PLGpW1TiqJtNdSRiIjEUj6c4hMRkWZIBUpERGJJBUpERGJJ\nBUpERGJJBUpERGJJBUpERGJJBUpERGJJBUpERGJJBUpERGJJBUpERGJJBUpERGJJBUpERGJJBUpE\nRGJJBUokA8xsiZl9N+ocIoVEBUpERGJJBUoki8zsx2a22Mw+NbOpZrZbYrmZ2f+Y2Qoz+8zM3jSz\nXol1Q83sLTNba2bLzOz/RftbiERDBUokS8zsO8BvgNMIM6p+AExKrP4ecBSwL7BzYpva6b3vAn7i\n7m2BXsAzOYwtEhuxn/JdJI+dDkx099cBzOynwL/MrBzYCLQF9gdedfcFSe/bCPQwszfc/V/Av3Ka\nWiQmdAQlkj27EY6aAHD3zwlHSd3c/RngVmA8sMLMJpjZTolNTwWGAh+Y2bNmdmiOc4vEggqUSPYs\nB/asfWFmOwIdgGUA7n6Lu/cDehBO9V2eWP6au58MdAYeBR7KcW6RWFCBEsmcYjMrqX0ADwLnmFkf\nM2sF/Bp4xd2XmNnBZnaImRUDXwDrgc1m1tLMTjeznd19I/AZsDmy30gkQipQIpkzDViX9BgE/AKY\nAnwE7A2MSmy7E3An4frSB4RTf79NrDsTWGJmnwHnEa5liTQ75u5RZxAREfkGHUGJiEgsqUCJiEgs\nqUCJiEgsqUCJiEgsRTaSRMeOHb28vDyqjxcRkYjMnj17pbt3ami7yApUeXk5lZWVUX28iIhExMw+\naHgrneITEZGYyt8C5Q7XXQcrVkSdREREsiB/C9Rbb8Gvfw0DB8LChVGnERGRDMvf6TZ69oSZM+HE\nE+Gww+CRR+Doo6NOJSKyTRs3bqSqqor169dHHSXrSkpKKCsro7i4eLven78FCmDAAHj5ZRg6FI45\nBiZOhDPOiDqViEi9qqqqaNu2LeXl5ZhZ1HGyxt1ZtWoVVVVVdO/efbv2kb+n+Gp17w4vvgiHHw5n\nngnXXhuuT4mIxND69evp0KFDQRcnADOjQ4cOTTpSzP8CBdC+PUyfHgrU1VfDuefChg1RpxIRSanQ\ni1Otpv6e+X2KL1nLlnDPPbDXXvCrX8GHH8KUKdCuXdTJRERkOxTGEVQtM7jmGrj7bnjuuXDab8mS\niEOJiMTH6tWrue222xr9vqFDh7J69eosJKpfYRWoWmefHU75LVsWuqFrxAoREaD+AlVTU7PN902b\nNo12OT4jVZgFCuDb34aXXoLWrUP388ceizqRiEjkxo0bx7vvvkufPn04+OCDOfLIIznppJPo0aMH\nAKeccgr9+vWjZ8+eTJgw4ev3lZeXs3LlSpYsWUJFRQU//vGP6dmzJ9/73vdYt25dVrIWzjWoVCoq\nQjf0E0+EYcPgf/4HLroo6lQiIsHFF8OcOZndZ58+cPPN9a6+/vrrmTdvHnPmzGHmzJkcf/zxzJs3\n7+uu4BMnTmSXXXZh3bp1HHzwwZx66ql06NBhq30sWrSIBx98kDvvvJPTTjuNKVOmcEYWbvFJ6wjK\nzIaY2dtmttjMxtWzzSAzm2Nm883s2czGbIIuXcINvaecEv5juOgi2LQp6lQiIrEwYMCAre5TuuWW\nWzjwwAMZOHAgS5cuZdGiRd94T/fu3enTpw8A/fr1Y0mWrvU3eARlZkXAeOAYoAp4zcymuvtbSdu0\nA24Dhrj7h2bWOStpt1dpKfz1r3D55eEoaskSeOAB2HHHqJOJSHO2jSOdXNkx6Xtw5syZPP3007z0\n0kuUlpYyaNCglPcxtWrV6uvnRUVFWTvFl84R1ABgsbu/5+4bgEnAyXW2+QHwsLt/CODu8RvBtagI\nbroJ/vAHeOKJcF3q44+jTiUiklNt27Zl7dq1KdetWbOG9u3bU1paysKFC3n55ZdznG5r6RSobsDS\npNdViWXJ9gXam9lMM5ttZmel2pGZjTGzSjOrrK6u3r7ETTV2LDz6KCxYAIccAvPnR5NDRCQCHTp0\n4PDDD6dXr15cfvnlW60bMmQINTU1VFRUMG7cOAYOHBhRysC8gWGBzGw44dTdvyVenwkc4u5jk7a5\nFegPDAZaAy8Bx7v7O/Xtt3///h7phIWzZ8MJJ8C6deGG3sGDo8siIs3GggULqKioiDpGzqT6fc1s\ntrv3b+i96RxBLQN2T3pdlliWrAqY7u5fuPtKYBZwYBr7jk6/fvDKK1BWBkOGhJt7RUQkNtIpUK8B\n+5hZdzNrCYwCptbZ5jHgCDPbwcxKgUOABZmNmgV77AEvvACDBsE558AvfqGBZkVEYqLBAuXuNcBY\nYDqh6Dzk7vPN7DwzOy+xzQLg78Bc4FXgT+4+L3uxM2jnnWHaNPjRj8IMvWeeCV99FXUqEZFmL60b\ndd19GjCtzrI76rz+LfDbzEXLoeJiuPPOMNDsz34GS5eGCRB32SXqZCIizVbhDnXUWGZw1VXh/qiX\nXw6z9L77btSpRESaLRWoukaPhqefhurqMNBsxPcBiIg0VypQqRx5ZBhoduedw6CzU6ZEnUhEJBJt\n2rQBYPny5QwfPjzlNoMGDSIbtw2pQNVn331DkTroIBgxAm68UT38RKTZ2m233Zg8eXJOP1MFals6\ndYJ//AOGDw/j+F1wATQwZ4qISJyNGzeO8ePHf/36mmuu4brrrmPw4MH07duXAw44gMdSTE+0ZMkS\nevXqBcC6desYNWoUFRUVDBs2TNNtRKZ1a5g0KfTwu+EG+OCD8Lpt26iTiUiei2C2DUaOHMnFF1/M\nBRdcAMBPA8WlAAARHklEQVRDDz3E9OnTufDCC9lpp51YuXIlAwcO5KSTTsLMUu7j9ttvp7S0lAUL\nFjB37lz69u2b2V8iQQUqHS1awPXXhyL17/8ORx0VBpztVndIQhGReDvooINYsWIFy5cvp7q6mvbt\n29O1a1cuueQSZs2aRYsWLVi2bBmffPIJXbt2TbmPWbNmceGFFwLQu3dvevfunZWsKlCNMWZMGH1i\nxIgw0Ozf/gYHxntEJxGJr6hm2xgxYgSTJ0/m448/ZuTIkdx///1UV1cze/ZsiouLKS8vTznNRq7p\nGlRjDRkCzz8fnh9xBPz979HmERFppJEjRzJp0iQmT57MiBEjWLNmDZ07d6a4uJgZM2bwwQcfbPP9\nRx11FA888AAA8+bNY+7cuVnJqQK1PQ48MNwftffeYUT0CROiTiQikraePXuydu1aunXrxq677srp\np59OZWUlBxxwAPfeey/777//Nt9//vnn8/nnn1NRUcHVV19Nv379spKzwek2siXy6TYyYe1aOO20\ncBR15ZXw61+H61UiIvXQdBuZnW5D6tO2LTz+OJx3XujhN3o0xOC8rYhIIVAniabaYQe47bbQw++K\nK6CqCh57DDp2jDqZiEhe0xFUJpiFG3n/+ld4/XU49FBYtCjqVCISU1FdWsm1pv6eKlCZNHw4PPMM\nrF4dBpqt7e0nIpJQUlLCqlWrCr5IuTurVq2ipKRku/ehU3yZduihoYff0KEweHCYSn706KhTiUhM\nlJWVUVVVRXV1ddRRsq6kpISysrLtfr8KVDbsvTe8+CIMGwY/+AEsWQLjxoVTgSLSrBUXF9O9e/eo\nY+SFtE7xmdkQM3vbzBab2bgU6weZ2Rozm5N4XJ35qHmmQwf4v/8LBeqqq+DHP4aNG6NOJSKSNxo8\ngjKzImA8cAxQBbxmZlPd/a06mz7n7idkIWP+atUK7rsv9PC77jr48MPQkWLnnaNOJiISe+kcQQ0A\nFrv7e+6+AZgEnJzdWAXEDK69Fu66C2bMCMMjffhh1KlERGIvnQLVDVia9Loqsayuw8xsrpk9aWY9\nU+3IzMaYWaWZVTaHC4RbOfdcePLJUJwGDgzd0UVEpF6Z6mb+OrCHu/cG/gA8mmojd5/g7v3dvX+n\nTp0y9NF55LvfhRdegOLiLVN2iIhISukUqGXA7kmvyxLLvubun7n754nn04BiM9NQCqn06hW6oe+3\nH5x8MiTNbCkiIlukU6BeA/Yxs+5m1hIYBUxN3sDMulpi6kUzG5DY76pMhy0Yu+4Kzz4Lxx8PY8fC\nZZfB5s1RpxIRiZUGe/G5e42ZjQWmA0XARHefb2bnJdbfAQwHzjezGmAdMMoL/TbppmrTBh55BC65\nBG66Kdwr9ec/Q2lp1MlERGJB023Ewe9/HwrVwQfD1KnQpUvUiUREskbTbeSTiy6Chx+GN98MPfwW\nLIg6kYhI5FSg4uKUU8J1qS+/hMMOg5kzo04kIhIpFag4OfhgeOWV0Inie98L16RERJopFai4KS8P\nA80ecQScdRb86leg/iYi0gypQMVRu3bw97+HAnXNNfDDH8KGDVGnEhHJKU23EVctW4a5pPbeG375\nS1i6NHSkaNcu6mQiIjmhI6g4M4Orr4Z77w2z8x52WLhfSkSkGVCBygdnnglPPQUffQSHHAKvvhp1\nIhGRrFOByheDBoXOEzvuGJ4/mnI8XhGRgqEClU8qKsJAs717w/e/DzffrB5+IlKwVKDyTefO8Mwz\n4cbeSy6BCy+ETZuiTiUiknEqUPmotDRMHX/ppXDrraFYff551KlERDJKBSpfFRXB734XCtS0aXD0\n0aEThYhIgVCByncXXACPPQZvvx0Gmp03L+pEIiIZoQJVCE44AWbNgo0b4fDD4emno04kItJkKlCF\nom/fMNDsnnvCccfBxIlRJxIRaZK0CpSZDTGzt81ssZmN28Z2B5tZjZkNz1zE1DZvht/8Jhw4fPVV\ntj8tT+y+exhx4jvfgR/9CH7+c3VDF5G81eBYfGZWBIwHjgGqgNfMbKq7v5ViuxuAp7IRtK5334Wf\n/Sx8/5aUhFGAvv3tcA/rgAFhKLtmaaed4Ikn4N//Hf7rv+C99+B//xdatYo6mYhIo6QzWOwAYLG7\nvwdgZpOAk4G36mz3H8AU4OCMJqzHPvvAqlXhCGrmTJgxA37xi7CutDRcihk0KBSt/v2huDgXqWKi\nuBgmTIC99oKrroKqKnjkEejQIepkIiJpS6dAdQOWJr2uAg5J3sDMugHDgG+TowIF0L49nHxyeMA3\nC9bPfhaW77hjmF6ptmD16wc7FPo47mbw059C9+5w9tlw6KHw5JNhdHQRkTyQqa/pm4Er3X2zmdW7\nkZmNAcYA7LHHHhn66C06dIBhw8IDYOXKMIt6bcH66U/D8jZt4MgjtxSsgw4q4II1ahSUlYUqPnAg\nTJ0aipWISMyZN3AR3cwOBa5x92MTr38K4O6/SdrmfaC2MnUEvgTGuHu9I5r279/fKysrm5a+kVas\n2LpgLVgQlu+009YFq0+fcB9sQVm0CIYODfNK/fnPMGJE1IlEpJkys9nu3r/B7dIoUDsA7wCDgWXA\na8AP3H1+PdvfDTzh7pO3td8oClRdn3yypVjNnBnudQXYeWc46qgtBevAA6FFIXTIX7kyHEm9+CLc\ncANcfnk4FSgikkPpFqgGT2y5e42ZjQWmA0XARHefb2bnJdbf0eS0EenSBUaODA+A5cvDEVZtwXr8\n8bC8fftQsGp7CR5wQJ4WrI4d4R//CFPIX3ll6OF3660FfH5TRPJZg0dQ2RKHI6iGVFVtXbDefTcs\n32WXMPRdbcHq2TPPCtbmzaEHyfXXw5Ah8NBD0LZt1KlEpJnI2Cm+bMmHAlXX0qVbnxJ8//2wvGPH\nrQtWjx55cubszjvh/POhV69w71RZWdSJRKQZUIHKgSVLQqGqLVoffhiWd+q05frVoEGw//4xLljT\np4cOE23bwt/+FnqIiIhkkQpUjrmHglV7dDVjRjhFCNC1ayhUtUVrn31iVrDmzoXjj4fVq8PpvuOO\nizqRiBQwFaiIuYc+CMkFa/nysG633bYuWHvvHYOCtWxZGBX9zTdh/Hj4yU8iDiQihUoFKmbcYfHi\nrQvWxx+Hdd26bTkd+O1vh8EfIilYa9eGG3unTYMrrgij8eZV7w8RyQcqUDHnDu+8EwpVbdFasSKs\n22OPra9hlZfnMFhNDVx4Idx+e7ghrE0baN06DHBYWrrleX0/G7uuVasYHD6KSC6pQOUZ9zCyRXIv\nwZUrw7ry8q0LVhZGifpmmD//GV59Fdatgy+/3PIz+Xndn5s3N/6zzJpW9BpTGIuLVQxFYkAFKs+5\nw/z5WwrWs8+GwXAhDFKeXLBi0TvcPczo21ARS6fQpbPN9igqyl7xq/tTNz+L1EsFqsBs3gzz5m1d\nsP71r7DuW9/aumDttluEQXPBPcxS2VARy0ShXL9++zIWFzd8arOoqGmPFi2avo9cfb6OXCWJClSB\n27w59A5PLlhr1oR1++67dcHq2jXCoPlu8+ZQqDJ9RPjVV7Bp0/Y/8m2mZLPcFkizLUVRz7d+3tT3\nH3MM9O79zX/jRlCBamY2bYI33thy/WrWLPjss7Bu//23FKtBg6Bz5wiDSma4h3/0zZubVuia+ojy\n87f12bXfa+7N+3k2/PGPMGZMk3ahAtXM1dTAnDlbCtZzz4Ve5BCGYqotWEcfHUa+EJECVlu4MlH4\nWrWCli2bFEcFSrZSUwOvv751wfrii7CuV6+tC1Y+zwxfe2CxaVP4nVP9cZ3t5em8p0WL7eubUVwc\ndQuLNJ0KlGzTxo0we/aWgvX881s6x/XuHQrW7rtH8wXflOX5cGnGbPtzFhU1vYNhutsU3KSdEhsq\nUNIoGzZAZeWWgvXCC+F6fl2prnXvsEPq69RRLY9jpuTltQVq/frsdDxM1R9jexQXZ7cnfu3P1q01\nYEkqmzeHP77qPmr/KItq+WmnwWGHNe13y9iEhdI8tGwZ/qM77LAwVdTGjeELLlXHKWm62vuTW7cO\n84tlU30dEZtSBFetCtPP1F23ceP2ZSwpydz92q1abX1kHZcv+cbuIy5q/8CqffTp0/QClS4VKEmp\nuFjXOwpFixaw447hkW01NVsXw6YeEX75ZeiNmmrdpk3Z+z2Sv5TrfkGnu7y0tOHtt3ff2ViealmL\nFtHewpZWgTKzIcDvgSLgT+5+fZ31JwPXApuBGuBid38+w1lFJOZ22CFMLZaLCZrrG7hk/fqmfWnr\nvuL4aLBAmVkRMB44BqgCXjOzqe7+VtJm/wCmurubWW/gIWD/bAQWEYFwhL/zzuEhhSmdKwoDgMXu\n/p67bwAmAScnb+Dun/uW3hY7AnnQl0pEROIsnQLVDVia9LoqsWwrZjbMzBYCfwPOTbUjMxtjZpVm\nVlldXb09eUVEpJnIWCcJd38EeMTMjiJcj/puim0mABMAzKzazD7IwEd3BFZmYD+5kE9ZQXmzKZ+y\nQn7lzaes0Dzz7pnORukUqGXA7kmvyxLLUnL3WWa2l5l1dPd6fwl3z8gAO2ZWmU5/+jjIp6ygvNmU\nT1khv/LmU1ZQ3m1J5xTfa8A+ZtbdzFoCo4CpyRuY2bfMQr8XM+sLtAJWZTqsiIg0Hw0eQbl7jZmN\nBaYTuplPdPf5ZnZeYv0dwKnAWWa2EVgHjPSohqgQEZGCkNY1KHefBkyrs+yOpOc3ADdkNlraJkT0\nudsjn7KC8mZTPmWF/MqbT1lBeesV2Vh8IiIi26KR1UREJJZUoEREJJbyokCZ2RAze9vMFpvZuBTr\nzcxuSayfm+hJGJk08g4yszVmNifxuDqKnIksE81shZnNq2d93Nq2obxxatvdzWyGmb1lZvPN7KIU\n28SmfdPMG4v2NbMSM3vVzN5IZP1Vim3i1Lbp5I1F2yblKTKzf5rZEynW5aZt3T3WD0LPwXeBvYCW\nwBtAjzrbDAWeBAwYCLwS87yDgCeibttElqOAvsC8etbHpm3TzBuntt0V6Jt43hZ4J+b/7aaTNxbt\nm2ivNonnxcArwMAYt206eWPRtkl5LgUeSJUpV22bD0dQDY4FmHh9rwcvA+3MbNdcB01IJ29suPss\n4NNtbBKntk0nb2y4+0fu/nri+VpgAd8cJiw27Ztm3lhItNfniZfFiUfdHl9xatt08saGmZUBxwN/\nqmeTnLRtPhSodMYCTGu8wBxJN8thiUPjJ82sZ26ibZc4tW26Yte2ZlYOHET4yzlZLNt3G3khJu2b\nOAU1B1gB/J+7x7pt08gLMWlb4GbgCsIUSqnkpG3zoUAVoteBPdy9N/AH4NGI8xSS2LWtmbUBphDm\nSfss6jwNaSBvbNrX3Te5ex/C8GsDzKxXVFnSkUbeWLStmZ0ArHD32VF8frJ8KFDpjAXYqPECs6zB\nLO7+We3hvoeboIvNrGPuIjZKnNq2QXFrWzMrJnzZ3+/uD6fYJFbt21DeuLVvIsdqYAYwpM6qWLVt\nrfryxqhtDwdOMrMlhEsU3zGz++psk5O2zYcC1eBYgInXZyV6lgwE1rj7R7kOmpDO2IVdzb4eu3AA\n4d8hrmMXxqltGxSntk3kuAtY4O431bNZbNo3nbxxaV8z62Rm7RLPWxMmVF1YZ7M4tW2DeePStu7+\nU3cvc/dywvfXM+5+Rp3NctK2GZtuI1s8vbEApxF6lSwGvgTOiXne4cD5ZlZDGLtwlCe6xuSamT1I\n6D3U0cyqgF8SLuDGrm0hrbyxaVvCX6JnAm8mrj0AXAXsAbFs33TyxqV9dwXusTDjdwvgIXd/Iq7f\nC6SXNy5tm1IUbauhjkREJJby4RSfiIg0QypQIiISSypQIiISSypQIiISSypQIiISSypQIiISSypQ\nIiISS/8fsgqd8z6FCy8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e89f250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = [x[0] for x in history]\n",
    "val_losses = [x[1] for x in history]\n",
    "accs = [x[2] for x in history]\n",
    "val_accs = [x[3] for x in history]\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(accs, color=\"r\", label=\"train\")\n",
    "plt.plot(val_accs, color=\"b\", label=\"valid\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(losses, color=\"r\", label=\"train\")\n",
    "plt.plot(val_losses, color=\"b\", label=\"valid\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test/Evaluate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = CNNLSTM(FRAME_SIZE, 1, 2, 2, 1, 1, 2, SEQUENCE_LENGTH, 50, 1, 2)\n",
    "saved_model.load_state_dict(torch.load(MODEL_FILE.format(5)))\n",
    "if torch.cuda.is_available():\n",
    "    saved_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.988\n",
      "Confusion matrix\n",
      "[[210   4]\n",
      " [  2 264]]\n"
     ]
    }
   ],
   "source": [
    "ylabels, ypreds = [], []\n",
    "num_test_batches = Xtest.shape[0] // BATCH_SIZE\n",
    "for bid in range(num_test_batches):\n",
    "    Xbatch_data = Xtest[bid * BATCH_SIZE : (bid + 1) * BATCH_SIZE]\n",
    "    ybatch_data = ytest[bid * BATCH_SIZE : (bid + 1) * BATCH_SIZE]\n",
    "    Xbatch = Variable(torch.from_numpy(Xbatch_data).float())\n",
    "    ybatch = Variable(torch.from_numpy(ybatch_data).long())\n",
    "    if torch.cuda.is_available():\n",
    "        Xbatch = Xbatch.cuda()\n",
    "        ybatch = ybatch.cuda()\n",
    "\n",
    "    Ybatch_ = saved_model(Xbatch)\n",
    "    _, ybatch_ = Ybatch_.max(1)\n",
    "    if torch.cuda.is_available():\n",
    "        ylabels.extend(ybatch.cpu().data.numpy())\n",
    "        ypreds.extend(ybatch_.cpu().data.numpy())\n",
    "    else:\n",
    "        ylabels.extend(ybatch.data.numpy())\n",
    "        ypreds.extend(ybatch_.data.numpy())\n",
    "\n",
    "print(\"Test accuracy: {:.3f}\".format(accuracy_score(ylabels, ypreds)))\n",
    "print(\"Confusion matrix\")\n",
    "print(confusion_matrix(ylabels, ypreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(NUM_EPOCHS):\n",
    "    os.remove(MODEL_FILE.format(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
