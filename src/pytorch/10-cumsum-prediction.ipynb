{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative Sum Prediction\n",
    "\n",
    "This is the fifth toy example from Jason Brownlee's [Long Short Term Memory Networks with Python](https://machinelearningmastery.com/lstms-with-python/). It demonstrates the solution to a sequence-to-sequence (aka seq2seq) prediction problem. Per section 10.2 of the book:\n",
    "\n",
    "> The problem is defined as a sequence of random values between 0 and 1. This sequence is taken as input for the problem with each number provided once per time step. A binary label (0 or 1) is associated with each input. The output values are initially all 0. Once the cumulative sum of the input values in the sequence exceeds a threshold, then the output value  flips from 0 to 1. A threshold of one quarter (1/4) of the sequence length is used, so for a sequence of length 10, the threshold is 2.5.\n",
    "\n",
    "> We will frame the problem to make the best use of the Bidirectional LSTM architecture.\n",
    "The output sequence will be produced after the entire input sequence has been fed into the\n",
    "model. Technically, this means this is a sequence-to-sequence prediction problem that requires\n",
    "a many-to-many prediction model. It is also the case that the input and output sequences have\n",
    "the same number of time steps (length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\"\n",
    "MODEL_FILE = os.path.join(DATA_DIR, \"torch-10-cumsum-predict-{:d}.model\")\n",
    "\n",
    "TRAIN_SIZE = 7500\n",
    "VAL_SIZE = 100\n",
    "TEST_SIZE = 500\n",
    "\n",
    "SEQ_LENGTH = 10\n",
    "EMBED_SIZE = 1\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04742344  0.93090249  0.47292869  0.34986938  0.27752548  0.22485943\n",
      "  0.05711298  0.38595953  0.78495727  0.13500855]\n",
      "[0 0 0 0 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "def generate_sequence(seq_len):\n",
    "    xs = np.random.random(seq_len)\n",
    "    ys = np.array([0 if x < 2.5 else 1 for x in np.cumsum(xs).tolist()])\n",
    "    return xs, ys\n",
    "\n",
    "X, Y = generate_sequence(SEQ_LENGTH)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 10, 1) (7500, 10) (100, 10, 1) (100, 10) (500, 10, 1) (500, 10)\n"
     ]
    }
   ],
   "source": [
    "def generate_data(seq_len, num_seqs):\n",
    "    xseq, yseq = [], []\n",
    "    for i in range(num_seqs):\n",
    "        X, Y = generate_sequence(seq_len)\n",
    "        xseq.append(X)\n",
    "        yseq.append(Y)\n",
    "    return np.expand_dims(np.array(xseq), axis=2), np.array(yseq)\n",
    "\n",
    "Xtrain, Ytrain = generate_data(SEQ_LENGTH, TRAIN_SIZE)\n",
    "Xval, Yval = generate_data(SEQ_LENGTH, VAL_SIZE)\n",
    "Xtest, Ytest = generate_data(SEQ_LENGTH, TEST_SIZE)\n",
    "\n",
    "print(Xtrain.shape, Ytrain.shape, Xval.shape, Yval.shape, Xtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network\n",
    "\n",
    "The sequence length for the input and output sequences are the same size. Our network follows the model built (using Keras) in the book. Unlike the typical encoder-decoder LSTM architecture that is used for most seq2seq problems, here we have a single LSTM followed by a FCN layer at each timestep of its output. Each FCN returns a binary 0/1 output, which is concatenated to produce the predicted result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CumSumPredictor (\n",
      "  (enc_lstm): LSTM(1, 50, batch_first=True, bidirectional=True)\n",
      "  (fcn): Linear (100 -> 2)\n",
      "  (fcn_relu): ReLU ()\n",
      "  (fcn_softmax): Softmax ()\n",
      ")\n",
      "--- size debugging ---\n",
      "torch.Size([32, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "class CumSumPredictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, seq_len, input_dim, hidden_dim, output_dim):\n",
    "        super(CumSumPredictor, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        # network layers\n",
    "        self.enc_lstm = nn.LSTM(input_dim, hidden_dim, 1, batch_first=True, \n",
    "                                bidirectional=True)\n",
    "        self.fcn = nn.Linear(hidden_dim * 2, output_dim)  # bidirectional input\n",
    "        self.fcn_relu = nn.ReLU()\n",
    "        self.fcn_softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if torch.cuda.is_available():\n",
    "            h = (Variable(torch.randn(2, x.size(0), self.hidden_dim).cuda()),\n",
    "                 Variable(torch.randn(2, x.size(0), self.hidden_dim).cuda()))\n",
    "        else:\n",
    "            h = (Variable(torch.randn(2, x.size(0), self.hidden_dim)),\n",
    "                 Variable(torch.randn(2, x.size(0), self.hidden_dim)))\n",
    "\n",
    "        x, h = self.enc_lstm(x, h)       # encoder LSTM\n",
    "        x_fcn = Variable(torch.zeros(x.size(0), self.seq_len, self.output_dim))\n",
    "        for i in range(self.seq_len):    # decoder LSTM -> fcn for each timestep\n",
    "            x_fcn[:, i, :] = self.fcn_softmax(self.fcn_relu(self.fcn(x[:, i, :])))\n",
    "        x = x_fcn        \n",
    "        return x\n",
    "    \n",
    "model = CumSumPredictor(SEQ_LENGTH, EMBED_SIZE, 50, 2)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "print(model)\n",
    "\n",
    "# size debugging\n",
    "print(\"--- size debugging ---\")\n",
    "inp = Variable(torch.randn(BATCH_SIZE, SEQ_LENGTH, EMBED_SIZE))\n",
    "outp = model(inp)\n",
    "print(outp.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/10: loss=4.743, acc=0.254, val_loss=4.109, val_acc=0.323\n",
      "Epoch  2/10: loss=3.827, acc=0.464, val_loss=3.728, val_acc=0.510\n",
      "Epoch  3/10: loss=3.640, acc=0.569, val_loss=3.647, val_acc=0.521\n",
      "Epoch  4/10: loss=3.562, acc=0.627, val_loss=3.597, val_acc=0.594\n",
      "Epoch  5/10: loss=3.527, acc=0.651, val_loss=3.570, val_acc=0.635\n",
      "Epoch  6/10: loss=3.500, acc=0.676, val_loss=3.542, val_acc=0.667\n",
      "Epoch  7/10: loss=3.484, acc=0.684, val_loss=3.496, val_acc=0.635\n",
      "Epoch  8/10: loss=3.460, acc=0.706, val_loss=3.580, val_acc=0.552\n",
      "Epoch  9/10: loss=3.454, acc=0.710, val_loss=3.468, val_acc=0.708\n",
      "Epoch 10/10: loss=3.433, acc=0.731, val_loss=3.469, val_acc=0.719\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(pred_var, true_var):\n",
    "    if torch.cuda.is_available():\n",
    "        ypred = pred_var.cpu().data.numpy()\n",
    "        ytrue = true_var.cpu().data.numpy()\n",
    "    else:\n",
    "        ypred = pred_var.data.numpy()\n",
    "        ytrue = true_var.data.numpy()\n",
    "    pred_nums, true_nums = [], []\n",
    "    for i in range(pred_var.size(0)): # for each row of output\n",
    "        pred_nums.append(int(\"\".join([str(x) for x in ypred[i].tolist()]), 2))\n",
    "        true_nums.append(int(\"\".join([str(x) for x in ytrue[i].tolist()]), 2))\n",
    "    return pred_nums, true_nums, accuracy_score(pred_nums, true_nums)\n",
    "\n",
    "\n",
    "history = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    num_batches = Xtrain.shape[0] // BATCH_SIZE\n",
    "    shuffled_indices = np.random.permutation(np.arange(Xtrain.shape[0]))\n",
    "    train_loss, train_acc = 0., 0.\n",
    "    \n",
    "    for bid in range(num_batches):\n",
    "        \n",
    "        # extract one batch of data\n",
    "        Xbatch_data = Xtrain[shuffled_indices[bid * BATCH_SIZE : (bid + 1) * BATCH_SIZE]]\n",
    "        Ybatch_data = Ytrain[shuffled_indices[bid * BATCH_SIZE : (bid + 1) * BATCH_SIZE]]\n",
    "        Xbatch = Variable(torch.from_numpy(Xbatch_data).float())\n",
    "        Ybatch = Variable(torch.from_numpy(Ybatch_data).long())\n",
    "        if torch.cuda.is_available():\n",
    "            Xbatch = Xbatch.cuda()\n",
    "            Ybatch = Ybatch.cuda()\n",
    "        \n",
    "        # initialize gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        loss = 0.\n",
    "        Ybatch_ = model(Xbatch)\n",
    "        for i in range(Ybatch.size(1)):\n",
    "            loss += loss_fn(Ybatch_[:, i, :], Ybatch[:, i])\n",
    "        \n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        _, ybatch_ = Ybatch_.max(2)\n",
    "        _, _, acc = compute_accuracy(ybatch_, Ybatch)\n",
    "        train_acc += acc\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    # compute training loss and accuracy\n",
    "    train_loss /= num_batches\n",
    "    train_acc /= num_batches\n",
    "    \n",
    "    # compute validation loss and accuracy\n",
    "    val_loss, val_acc = 0., 0.\n",
    "    num_val_batches = Xval.shape[0] // BATCH_SIZE\n",
    "    for bid in range(num_val_batches):\n",
    "        # data\n",
    "        Xbatch_data = Xval[bid * BATCH_SIZE : (bid + 1) * BATCH_SIZE]\n",
    "        Ybatch_data = Yval[bid * BATCH_SIZE : (bid + 1) * BATCH_SIZE]\n",
    "        Xbatch = Variable(torch.from_numpy(Xbatch_data).float())\n",
    "        Ybatch = Variable(torch.from_numpy(Ybatch_data).long())\n",
    "        if torch.cuda.is_available():\n",
    "            Xbatch = Xbatch.cuda()\n",
    "            Ybatch = Ybatch.cuda()\n",
    "\n",
    "        loss = 0.\n",
    "        Ybatch_ = model(Xbatch)\n",
    "        for i in range(Ybatch.size(1)):\n",
    "            loss += loss_fn(Ybatch_[:, i, :], Ybatch[:, i])\n",
    "        val_loss += loss.data[0]\n",
    "\n",
    "        _, ybatch_ = Ybatch_.max(2)\n",
    "        _, _, acc = compute_accuracy(ybatch_, Ybatch)\n",
    "        val_acc += acc\n",
    "        \n",
    "    val_loss /= num_val_batches\n",
    "    val_acc /= num_val_batches\n",
    "    \n",
    "    torch.save(model.state_dict(), MODEL_FILE.format(epoch+1))\n",
    "    print(\"Epoch {:2d}/{:d}: loss={:.3f}, acc={:.3f}, val_loss={:.3f}, val_acc={:.3f}\"\n",
    "          .format((epoch+1), NUM_EPOCHS, train_loss, train_acc, val_loss, val_acc))\n",
    "    \n",
    "    history.append((train_loss, val_loss, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwujKdt0aAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a37c5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = [x[0] for x in history]\n",
    "val_losses = [x[1] for x in history]\n",
    "accs = [x[2] for x in history]\n",
    "val_accs = [x[3] for x in history]\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(accs, color=\"r\", label=\"train\")\n",
    "plt.plot(val_accs, color=\"b\", label=\"valid\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(losses, color=\"r\", label=\"train\")\n",
    "plt.plot(val_losses, color=\"b\", label=\"valid\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved_model = CumSumPredictor(SEQ_LENGTH, EMBED_SIZE, 50, 2)\n",
    "saved_model.load_state_dict(torch.load(MODEL_FILE.format(NUM_EPOCHS)))\n",
    "if torch.cuda.is_available():\n",
    "    saved_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.746\n"
     ]
    }
   ],
   "source": [
    "ylabels, ypreds = [], []\n",
    "num_test_batches = Xtest.shape[0] // BATCH_SIZE\n",
    "for bid in range(num_test_batches):\n",
    "    Xbatch_data = Xtest[bid * BATCH_SIZE : (bid + 1) * BATCH_SIZE]\n",
    "    Ybatch_data = Ytest[bid * BATCH_SIZE : (bid + 1) * BATCH_SIZE]\n",
    "    Xbatch = Variable(torch.from_numpy(Xbatch_data).float())\n",
    "    Ybatch = Variable(torch.from_numpy(Ybatch_data).long())\n",
    "    if torch.cuda.is_available():\n",
    "        Xbatch = Xbatch.cuda()\n",
    "        Ybatch = Ybatch.cuda()\n",
    "\n",
    "    Ybatch_ = saved_model(Xbatch)\n",
    "    _, ybatch_ = Ybatch_.max(2)\n",
    "\n",
    "    pred_nums, true_nums, _ = compute_accuracy(ybatch_, Ybatch)\n",
    "    ylabels.extend(true_nums)\n",
    "    ypreds.extend(pred_nums)\n",
    "\n",
    "print(\"Test accuracy: {:.3f}\".format(accuracy_score(ylabels, ypreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=[0 0 0 0 0 0 1 1 1 1], yhat=[0 0 0 0 0 0 1 1 1 1], correct=True\n",
      "y=[0 0 0 0 0 1 1 1 1 1], yhat=[0 0 0 0 0 1 1 1 1 1], correct=True\n",
      "y=[0 0 0 0 0 0 1 1 1 1], yhat=[0 0 0 0 0 0 1 1 1 1], correct=True\n",
      "y=[0 0 0 0 0 0 0 1 1 1], yhat=[0 0 0 0 0 0 0 1 1 1], correct=True\n",
      "y=[0 0 0 0 0 0 1 1 1 1], yhat=[0 0 0 0 0 0 1 1 1 1], correct=True\n",
      "y=[0 0 0 0 0 0 1 1 1 1], yhat=[0 0 0 0 0 0 1 1 1 1], correct=True\n",
      "y=[0 0 0 0 1 1 1 1 1 1], yhat=[0 0 0 0 0 1 1 1 1 1], correct=False\n",
      "y=[0 0 0 0 1 1 1 1 1 1], yhat=[0 0 0 0 1 1 1 1 1 1], correct=True\n",
      "y=[0 0 0 0 1 1 1 1 1 1], yhat=[0 0 0 0 1 1 1 1 1 1], correct=True\n",
      "y=[0 0 0 1 1 1 1 1 1 1], yhat=[0 0 0 1 1 1 1 1 1 1], correct=True\n"
     ]
    }
   ],
   "source": [
    "Xbatch_data = Xtest[0:10]\n",
    "Ybatch_data = Ytest[0:10]\n",
    "Xbatch = Variable(torch.from_numpy(Xbatch_data).float())\n",
    "Ybatch = Variable(torch.from_numpy(Ybatch_data).long())\n",
    "if torch.cuda.is_available():\n",
    "    Xbatch = Xbatch.cuda()\n",
    "    Ybatch = Ybatch.cuda()\n",
    "\n",
    "Ybatch_ = saved_model(Xbatch)\n",
    "_, ybatch_ = Ybatch_.max(2)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    ybatch__data = ybatch_.cpu().data.numpy()\n",
    "else:\n",
    "    ybatch__data = ybatch_.data.numpy()\n",
    "\n",
    "for i in range(Ybatch_data.shape[0]):\n",
    "    label = Ybatch_data[i]\n",
    "    pred = ybatch__data[i]\n",
    "    correct = \"True\" if np.array_equal(label, pred) else \"False\"\n",
    "    print(\"y={:s}, yhat={:s}, correct={:s}\".format(str(label), str(pred), correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(NUM_EPOCHS):\n",
    "    os.remove(MODEL_FILE.format(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
