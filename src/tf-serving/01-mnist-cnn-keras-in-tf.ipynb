{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Recognition - Hybrid CNN w/Keras in TF\n",
    "\n",
    "MNIST Digit Recognition built using Keras built into Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\"\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"mnist_train.csv\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"mnist_test.csv\")\n",
    "\n",
    "OUTPUT_DATA_DIR = os.path.join(DATA_DIR, \"01-mnist-cnn\")\n",
    "LOG_DIR = os.path.join(OUTPUT_DATA_DIR, \"logs\")\n",
    "MODEL_FILE = os.path.join(OUTPUT_DATA_DIR, \"model\")\n",
    "\n",
    "IMG_SIZE = 28\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 10\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_train.csv: 0 lines read\n",
      "mnist_train.csv: 10000 lines read\n",
      "mnist_train.csv: 20000 lines read\n",
      "mnist_train.csv: 30000 lines read\n",
      "mnist_train.csv: 40000 lines read\n",
      "mnist_train.csv: 50000 lines read\n",
      "mnist_train.csv: 60000 lines read\n",
      "mnist_test.csv: 0 lines read\n",
      "mnist_test.csv: 10000 lines read\n",
      "(60000, 28, 28, 1) (60000,) (10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def parse_file(filename):\n",
    "    xdata, ydata = [], []\n",
    "    fin = open(filename, \"rb\")\n",
    "    i = 0\n",
    "    for line in fin:\n",
    "        if i % 10000 == 0:\n",
    "            print(\"{:s}: {:d} lines read\".format(\n",
    "                os.path.basename(filename), i))\n",
    "        cols = line.strip().split(\",\")\n",
    "        ydata.append(int(cols[0]))\n",
    "        xdata.append(np.reshape(np.array([float(x) / 255. \n",
    "            for x in cols[1:]]), (IMG_SIZE, IMG_SIZE, 1)))\n",
    "        i += 1\n",
    "    fin.close()\n",
    "    print(\"{:s}: {:d} lines read\".format(os.path.basename(filename), i))\n",
    "    y = np.array(ydata)\n",
    "    X = np.array(xdata)\n",
    "    return X, y\n",
    "\n",
    "Xtrain, ytrain = parse_file(TRAIN_FILE)\n",
    "Xtest, ytest = parse_file(TEST_FILE)\n",
    "print(Xtrain.shape, ytrain.shape, Xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 28, 28, 1) (128, 10)\n"
     ]
    }
   ],
   "source": [
    "def datagen(X, y, batch_size=BATCH_SIZE, num_classes=NUM_CLASSES):\n",
    "    ohe = OneHotEncoder(n_values=num_classes)\n",
    "    while True:\n",
    "        shuffled_indices = np.random.permutation(np.arange(len(y)))\n",
    "        num_batches = len(y) // batch_size\n",
    "        for bid in range(num_batches):\n",
    "            batch_indices = shuffled_indices[bid*batch_size:(bid+1)*batch_size]\n",
    "            Xbatch = np.zeros((batch_size, X.shape[1], X.shape[2], X.shape[3]))\n",
    "            Ybatch = np.zeros((batch_size, num_classes))\n",
    "            for i in range(batch_size):\n",
    "                Xbatch[i] = X[batch_indices[i]]\n",
    "                Ybatch[i] = ohe.fit_transform(y[batch_indices[i]]).todense()\n",
    "            yield Xbatch, Ybatch\n",
    "\n",
    "self_test_gen = datagen(Xtrain, ytrain)\n",
    "Xbatch, Ybatch = self_test_gen.next()\n",
    "print(Xbatch.shape, Ybatch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network\n",
    "\n",
    "The network is defined using Keras. The loss and accuracy also use Keras functions. However, we use a Tensorflow optimizer, as well as execute the whole thing in the context of a Tensorflow session. Note that we need to set the Keras session and pass in the value of learning_phase during training and evaluation.\n",
    "\n",
    "We also use the SummaryWriter to log the loss and accuracy at each step so they can be viewed using Tensorboard.\n",
    "\n",
    "Finally, and most importantly for our Tensorflow Serving experiment, we use the Tensorflow Saver to save the model in Tensorflow format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "tf.contrib.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"data\"):\n",
    "    X = tf.placeholder(tf.float32, [None, IMG_SIZE, IMG_SIZE, 1], name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32, [None, NUM_CLASSES], name=\"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = tf.contrib.keras.models.Sequential()\n",
    "model.add(tf.contrib.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", \n",
    "                                         input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(tf.contrib.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(tf.contrib.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.contrib.keras.layers.Dropout(0.25))\n",
    "model.add(tf.contrib.keras.layers.Flatten())\n",
    "model.add(tf.contrib.keras.layers.Dense(128, activation=\"relu\"))\n",
    "model.add(tf.contrib.keras.layers.Dropout(0.5))\n",
    "model.add(tf.contrib.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "\n",
    "Y_ = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.contrib.keras.losses.categorical_crossentropy(Y, Y_))\n",
    "accuracy = tf.reduce_mean(tf.contrib.keras.metrics.categorical_accuracy(Y, Y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(OUTPUT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.summary.scalar(\"loss\", loss)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "# Merge all summaries into a single op\n",
    "summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: loss=0.245, accuracy=0.926\n",
      "Epoch 2/5: loss=0.086, accuracy=0.975\n",
      "Epoch 3/5: loss=0.060, accuracy=0.982\n",
      "Epoch 4/5: loss=0.051, accuracy=0.984\n",
      "Epoch 5/5: loss=0.044, accuracy=0.986\n"
     ]
    }
   ],
   "source": [
    "with sess.as_default():\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    logger = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
    "    \n",
    "    train_gen = datagen(Xtrain, ytrain, BATCH_SIZE)\n",
    "    num_batches = len(Xtrain) // BATCH_SIZE\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        total_loss, total_acc = 0, 0\n",
    "        for bid in range(num_batches):\n",
    "            Xbatch, Ybatch = train_gen.next()\n",
    "            _, batch_loss, batch_acc, batch_summary = sess.run(\n",
    "                [optimizer, loss, accuracy, summary], \n",
    "                feed_dict={X: Xbatch, Y: Ybatch, tf.contrib.keras.backend.learning_phase(): 1})\n",
    "            \n",
    "            # write to tensorboard\n",
    "            logger.add_summary(batch_summary, epoch * num_batches + bid)\n",
    "            # accumulate to print once per epoch\n",
    "            total_acc += batch_acc\n",
    "            total_loss += batch_loss\n",
    "            \n",
    "        total_acc /= num_batches\n",
    "        total_loss /= num_batches\n",
    "        print(\"Epoch {:d}/{:d}: loss={:.3f}, accuracy={:.3f}\".format(\n",
    "            (epoch + 1), NUM_EPOCHS, total_loss, total_acc))\n",
    "        saver.save(sess, MODEL_FILE, (epoch + 1))\n",
    "        \n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training logs via Tensorboard\n",
    "\n",
    "On the command line, run following commands:\n",
    "\n",
    "    cd ../../data/01-tf-serving\n",
    "    tensorboard --logdir=logs\n",
    "    \n",
    "Control-Click on [http://localhost:6006](http://localhost:6006) to see loss and accuracy plots on the browser.\n",
    "\n",
    "Here are (representative) images from tensorboard for the accuracy and loss.\n",
    "\n",
    "<img src=\"01-tensorboard-lossplot.png\"/>\n",
    "\n",
    "\n",
    "## Evaluate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../data/01-tf-serving/model-5\n",
      "Accuracy: 0.9898\n",
      "Confusion Matrix\n",
      "[[5848    0    6    0    0   12   36    6   30    6]\n",
      " [   6 6773   12    0    0    0   12    6    6   18]\n",
      " [   0    6 6127   12    0    0    0   18   12    0]\n",
      " [   0    6    0 6017    0   48    0    6    6    0]\n",
      " [   0    0    6    0 5827    0    6    0    0   24]\n",
      " [   0    6    0   12    0 5270   30    0    0   30]\n",
      " [   6    6    0    0   17    6 5648    0    0    0]\n",
      " [   0    0   30    6    0    0    0 6117   30   18]\n",
      " [   0    0    0    6    6    6    6    6 5724   12]\n",
      " [   6    0    0    0   36    0    0    0   24 5942]]\n"
     ]
    }
   ],
   "source": [
    "BEST_MODEL = os.path.join(OUTPUT_DATA_DIR, \"model-5\")\n",
    "saver = tf.train.Saver()\n",
    "ys, ys_ = [], []\n",
    "with sess.as_default():\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, BEST_MODEL)\n",
    "    \n",
    "    test_gen = datagen(Xtest, ytest, BATCH_SIZE)\n",
    "    val_loss, val_acc = 0., 0.\n",
    "    num_batches = len(Xtrain) // BATCH_SIZE\n",
    "    for _ in range(num_batches):\n",
    "        Xbatch, Ybatch = test_gen.next()\n",
    "        Ybatch_ = sess.run(Y_, feed_dict={X: Xbatch, \n",
    "            tf.contrib.keras.backend.learning_phase(): 0})\n",
    "        ys.extend(np.argmax(Ybatch, axis=1))\n",
    "        ys_.extend(np.argmax(Ybatch_, axis=1))\n",
    "\n",
    "acc = accuracy_score(ys_, ys)\n",
    "cm = confusion_matrix(ys_, ys)\n",
    "print(\"Accuracy: {:.4f}\".format(acc))\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
