{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consume native Keras model served by TF-Serving\n",
    "\n",
    "This notebook shows client code needed to consume a native Keras model served by Tensorflow serving. The Tensorflow serving model needs to be started using the following command:\n",
    "\n",
    "    bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server \\\n",
    "        --port=9000 --model_name=keras-mnist-fcn \\\n",
    "        --model_base_path=/home/sujit/Projects/polydlot/data/tf-export/keras-mnist-fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from google.protobuf import json_format\n",
    "from grpc.beta import implementations\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONCURRENCY = 1\n",
    "NUM_TESTS = 10\n",
    "# NUM_TESTS = 1\n",
    "SERVER_HOST = \"localhost\"\n",
    "SERVER_PORT = 9000\n",
    "WORK_DIR = \"/tmp\"\n",
    "\n",
    "DATA_DIR = \"../../data\"\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"mnist_test.csv\")\n",
    "\n",
    "IMG_SIZE = 28\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_test.csv: 0 lines read\n",
      "mnist_test.csv: 10000 lines read\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def parse_file(filename):\n",
    "    xdata, ydata = [], []\n",
    "    fin = open(filename, \"rb\")\n",
    "    i = 0\n",
    "    for line in fin:\n",
    "        if i % 10000 == 0:\n",
    "            print(\"{:s}: {:d} lines read\".format(os.path.basename(filename), i))\n",
    "        cols = line.strip().split(\",\")\n",
    "        ydata.append(int(cols[0]))\n",
    "        xdata.append(np.reshape(np.array([float(x) / 255. for x in cols[1:]]), \n",
    "                     (IMG_SIZE*IMG_SIZE,)))\n",
    "        i += 1\n",
    "    fin.close()\n",
    "    print(\"{:s}: {:d} lines read\".format(os.path.basename(filename), i))\n",
    "    y = np.array(ydata, dtype=\"int32\")\n",
    "    X = np.array(xdata, dtype=\"float32\")\n",
    "    return X, y\n",
    "\n",
    "Xtest, ytest = parse_file(TEST_FILE)\n",
    "print(Xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channel = implementations.insecure_channel(SERVER_HOST, SERVER_PORT)\n",
    "stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)\n",
    "labels, predictions = [], []\n",
    "for i in range(Xtest.shape[0]):\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = \"keras-mnist-fcn\"\n",
    "    request.model_spec.signature_name = \"predict\"\n",
    "\n",
    "    Xbatch, ybatch = Xtest[i], ytest[i]\n",
    "    request.inputs[\"images\"].CopyFrom(\n",
    "        tf.contrib.util.make_tensor_proto(Xbatch, shape=[1, Xbatch.size]))\n",
    "\n",
    "    result = stub.Predict(request, 10.0)\n",
    "    result_json = json.loads(json_format.MessageToJson(result))\n",
    "    y_ = np.array(result_json[\"outputs\"][\"scores\"][\"floatVal\"], dtype=\"float32\")\n",
    "    labels.append(ybatch)\n",
    "    predictions.append(np.argmax(y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.983\n",
      "Confusion Matrix\n",
      "[[ 969    0    0    2    0    0    2    0    4    3]\n",
      " [   0 1127    1    2    0    0    2    0    3    0]\n",
      " [   2    2 1015    3    1    0    1    6    2    0]\n",
      " [   0    0    1 1000    0    1    0    3    3    2]\n",
      " [   0    0    4    0  952    0    3    2    2   19]\n",
      " [   2    0    0    8    2  872    2    1    5    0]\n",
      " [   1    2    1    1    1    5  945    0    2    0]\n",
      " [   1    3    9    2    0    0    0 1004    3    6]\n",
      " [   0    0    2    5    0    1    0    3  959    4]\n",
      " [   1    3    0    5    6    2    1    2    1  988]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: {:.3f}\".format(accuracy_score(labels, predictions)))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
