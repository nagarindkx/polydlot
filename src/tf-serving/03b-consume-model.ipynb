{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consume native Keras model served by TF-Serving\n",
    "\n",
    "This notebook shows client code needed to consume a native Keras model served by Tensorflow serving. The Tensorflow serving model needs to be started using the following command:\n",
    "\n",
    "    bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server \\\n",
    "        --port=9000 --model_name=keras-mnist-fcn \\\n",
    "        --model_base_path=/home/sujit/Projects/polydlot/data/tf-export/keras-mnist-fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from google.protobuf import json_format\n",
    "from grpc.beta import implementations\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONCURRENCY = 1\n",
    "# NUM_TESTS = 10\n",
    "NUM_TESTS = 1\n",
    "SERVER_HOST = \"localhost\"\n",
    "SERVER_PORT = 9000\n",
    "WORK_DIR = \"/tmp\"\n",
    "\n",
    "DATA_DIR = \"../../data\"\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"mnist_test.csv\")\n",
    "\n",
    "IMG_SIZE = 28\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_test.csv: 0 lines read\n",
      "mnist_test.csv: 10000 lines read\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def parse_file(filename):\n",
    "    xdata, ydata = [], []\n",
    "    fin = open(filename, \"rb\")\n",
    "    i = 0\n",
    "    for line in fin:\n",
    "        if i % 10000 == 0:\n",
    "            print(\"{:s}: {:d} lines read\".format(os.path.basename(filename), i))\n",
    "        cols = line.strip().split(\",\")\n",
    "        ydata.append(int(cols[0]))\n",
    "        xdata.append(np.reshape(np.array([float(x) / 255. for x in cols[1:]]), \n",
    "                     (IMG_SIZE*IMG_SIZE,)))\n",
    "        i += 1\n",
    "    fin.close()\n",
    "    print(\"{:s}: {:d} lines read\".format(os.path.basename(filename), i))\n",
    "    y = np.array(ydata, dtype=\"int32\")\n",
    "    X = np.array(xdata, dtype=\"float32\")\n",
    "    return X, y\n",
    "\n",
    "Xtest, ytest = parse_file(TEST_FILE)\n",
    "print(Xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _ResultCounter(object):\n",
    "    \"\"\" Counter for prediction results \"\"\"\n",
    "    def __init__(self, num_tests, concurrency):\n",
    "        self._num_tests = num_tests\n",
    "        self._concurrency = concurrency\n",
    "        self._error = 0\n",
    "        self._done = 0\n",
    "        self._active = 0\n",
    "        self._results = []\n",
    "        self._condition = threading.Condition()\n",
    "\n",
    "    def inc_error(self):\n",
    "        with self._condition:\n",
    "            self._error += 1\n",
    "            \n",
    "    def inc_done(self):\n",
    "        with self._condition:\n",
    "            self._done += 1\n",
    "            self._condition.notify()\n",
    "\n",
    "    def dec_active(self):\n",
    "        with self._condition:\n",
    "            self._active -= 1\n",
    "            self._condition.notify()\n",
    "    \n",
    "    def add_result(self, result):\n",
    "        with self._condition:\n",
    "            self._results.append(result)\n",
    "            self._condition.notify()\n",
    "            \n",
    "    def get_error_rate(self):\n",
    "        with self._condition:\n",
    "            while self._done != self._num_tests:\n",
    "                self._condition.wait()\n",
    "        return self._error / float(self._num_tests)\n",
    "\n",
    "    def throttle(self):\n",
    "        with self._condition:\n",
    "            while self._active == self._concurrency:\n",
    "                self._condition.wait()\n",
    "            self._active += 1\n",
    "\n",
    "\n",
    "def _create_rpc_callback(image, label, result_counter):\n",
    "    def _callback(result_future):\n",
    "        print(\"image\", image.shape, \"label\", label.shape)\n",
    "        exception = result_future.exception()\n",
    "        if exception:\n",
    "            result_counter.inc_error()\n",
    "            print(exception)\n",
    "        else:\n",
    "            sys.stdout.write('.')\n",
    "            sys.stdout.flush()\n",
    "        response = numpy.array(result_future.result().outputs['scores'].float_val)\n",
    "        prediction = numpy.argmax(response)\n",
    "#         label_ = numpy.argmax(label)\n",
    "        if label != prediction:\n",
    "            result_counter.inc_error()\n",
    "        result_counter.add_result((image, label, prediction))\n",
    "        result_counter.inc_done()\n",
    "        result_counter.dec_active()\n",
    "    return _callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs {\n",
      "  key: \"scores\"\n",
      "  value {\n",
      "    dtype: DT_FLOAT\n",
      "    tensor_shape {\n",
      "      dim {\n",
      "        size: 1\n",
      "      }\n",
      "      dim {\n",
      "        size: 10\n",
      "      }\n",
      "    }\n",
      "    float_val: 6.40141717412e-10\n",
      "    float_val: 3.63637688849e-08\n",
      "    float_val: 3.10336105258e-07\n",
      "    float_val: 6.09695644016e-06\n",
      "    float_val: 1.643126607e-10\n",
      "    float_val: 1.38603717392e-09\n",
      "    float_val: 2.09329970892e-12\n",
      "    float_val: 0.999953389168\n",
      "    float_val: 5.23174072953e-08\n",
      "    float_val: 4.01516335842e-05\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel = implementations.insecure_channel(SERVER_HOST, SERVER_PORT)\n",
    "stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)\n",
    "result_counter = _ResultCounter(NUM_TESTS, CONCURRENCY)\n",
    "tf.contrib.keras.backend.set_learning_phase(False)\n",
    "for i in range(NUM_TESTS):\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = \"keras-mnist-fcn\"\n",
    "    request.model_spec.signature_name = \"predict\"\n",
    "#     Xbatch, Ybatch = test_gen.next()\n",
    "#     Xbatch, Ybatch = Xtest[0:10], ytest[0:10]\n",
    "    request.inputs[\"images\"].CopyFrom(\n",
    "#         tf.contrib.util.make_tensor_proto(Xbatch[0], shape=Xbatch.shape))\n",
    "        tf.contrib.util.make_tensor_proto(Xtest[0], shape=[1, Xtest[0].size]))\n",
    "\n",
    "    result_counter.throttle()\n",
    "#     result_future = stub.Predict.future(request, 5.0)\n",
    "#     result_future.add_done_callback(_create_rpc_callback(Xtest[0], ytest[0], result_counter))\n",
    "    result = stub.Predict(request, 10.0)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,) [  6.40141717e-10   3.63637689e-08   3.10336105e-07   6.09695644e-06\n",
      "   1.64312661e-10   1.38603717e-09   2.09329971e-12   9.99953389e-01\n",
      "   5.23174073e-08   4.01516336e-05]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "message = json.loads(json_format.MessageToJson(result))\n",
    "# print(message)\n",
    "y_ = np.array(message[\"outputs\"][\"scores\"][\"floatVal\"], dtype=\"float32\")\n",
    "print(y_.shape, y_)\n",
    "y = np.argmax(y_)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
