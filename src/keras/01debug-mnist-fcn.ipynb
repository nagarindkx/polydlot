{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging MNIST Digit Classification - Fully Connected Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\"\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"mnist_train.csv\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"mnist_test.csv\")\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 10\n",
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_train.csv: 0 lines read\n",
      "mnist_train.csv: 10000 lines read\n",
      "mnist_train.csv: 20000 lines read\n",
      "mnist_train.csv: 30000 lines read\n",
      "mnist_train.csv: 40000 lines read\n",
      "mnist_train.csv: 50000 lines read\n",
      "mnist_train.csv: 60000 lines read\n",
      "mnist_test.csv: 0 lines read\n",
      "mnist_test.csv: 10000 lines read\n",
      "(60000, 784) (60000, 10) (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "def parse_file(filename):\n",
    "    xdata, ydata = [], []\n",
    "    fin = open(filename, \"rb\")\n",
    "    i = 0\n",
    "    for line in fin:\n",
    "        if i % 10000 == 0:\n",
    "            print(\"{:s}: {:d} lines read\".format(\n",
    "                os.path.basename(filename), i))\n",
    "        cols = line.strip().split(\",\")\n",
    "        ydata.append(int(cols[0]))\n",
    "        xdata.append([float(x) / 255. for x in cols[1:]])\n",
    "        i += 1\n",
    "    fin.close()\n",
    "    print(\"{:s}: {:d} lines read\".format(os.path.basename(filename), i))\n",
    "    Y = np_utils.to_categorical(np.array(ydata), num_classes=NUM_CLASSES)\n",
    "    X = np.array(xdata)\n",
    "    return X, Y\n",
    "\n",
    "Xtrain, Ytrain = parse_file(TRAIN_FILE)\n",
    "Xtest, Ytest = parse_file(TEST_FILE)\n",
    "print(Xtrain.shape, Ytrain.shape, Xtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network\n",
    "\n",
    "Model is identical to that defined in Keras example [mnist_mlp.py](https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation=\"relu\", input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_1 (?, 784) (?, 512)\n",
      "dropout_1 (?, 512) (?, 512)\n",
      "dense_2 (?, 512) (?, 256)\n",
      "dropout_2 (?, 256) (?, 256)\n",
      "dense_3 (?, 256) (?, 10)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name, layer.input.shape, layer.output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "            \n",
    "def calc_stats(W):\n",
    "    return np.linalg.norm(W, 2), np.mean(W), np.std(W)\n",
    "\n",
    "class MyDebugWeights(Callback):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyDebugWeights, self).__init__()\n",
    "        self.weights = []\n",
    "        self.tf_session = K.get_session()\n",
    "            \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for layer in self.model.layers:\n",
    "            name = layer.name\n",
    "            for i, w in enumerate(layer.weights):\n",
    "                w_value = w.eval(session=self.tf_session)\n",
    "                w_norm, w_mean, w_std = calc_stats(np.reshape(w_value, -1))\n",
    "                self.weights.append((epoch, \"{:s}/W_{:d}\".format(name, i), \n",
    "                                     w_norm, w_mean, w_std))\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        for e, k, n, m, s in self.weights:\n",
    "            print(\"{:3d} {:20s} {:7.3f} {:7.3f} {:7.3f}\".format(e, k, n, m, s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Network, collect weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/2\n",
      "54000/54000 [==============================] - 3s - loss: 0.0280 - acc: 0.9906 - val_loss: 0.0732 - val_acc: 0.9818\n",
      "Epoch 2/2\n",
      "54000/54000 [==============================] - 3s - loss: 0.0265 - acc: 0.9909 - val_loss: 0.0727 - val_acc: 0.9812\n",
      "  0 dense_1/W_0           42.340  -0.006   0.067\n",
      "  0 dense_1/W_1            0.733  -0.005   0.032\n",
      "  0 dense_2/W_0           29.111  -0.001   0.080\n",
      "  0 dense_2/W_1            0.776   0.015   0.046\n",
      "  0 dense_3/W_0            6.574  -0.017   0.129\n",
      "  0 dense_3/W_1            0.161  -0.006   0.051\n",
      "  1 dense_1/W_0           43.770  -0.007   0.069\n",
      "  1 dense_1/W_1            0.781  -0.005   0.034\n",
      "  1 dense_2/W_0           30.020  -0.002   0.083\n",
      "  1 dense_2/W_1            0.874   0.016   0.052\n",
      "  1 dense_3/W_0            6.704  -0.018   0.131\n",
      "  1 dense_3/W_1            0.189  -0.007   0.059\n"
     ]
    }
   ],
   "source": [
    "my_debug_weights = MyDebugWeights()\n",
    "history = model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE, \n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[my_debug_weights])\n",
    "\n",
    "# Train on 54000 samples, validate on 6000 samples\n",
    "# Epoch 1/2\n",
    "# 54000/54000 [==============================] - 4s - loss: 0.2830 - acc: 0.9146 - val_loss: 0.0979 - val_acc: 0.9718\n",
    "# Epoch 2/2\n",
    "# 54000/54000 [==============================] - 3s - loss: 0.1118 - acc: 0.9663 - val_loss: 0.0758 - val_acc: 0.9773\n",
    "#   0 dense_1/W_0           28.236  -0.002   0.045\n",
    "#   0 dense_1/W_1            0.283   0.003   0.012\n",
    "#   0 dense_2/W_0           20.631   0.002   0.057\n",
    "#   0 dense_2/W_1            0.205   0.008   0.010\n",
    "#   0 dense_3/W_0            4.962  -0.005   0.098\n",
    "#   0 dense_3/W_1            0.023  -0.001   0.007\n",
    "#   1 dense_1/W_0           30.455  -0.003   0.048\n",
    "#   1 dense_1/W_1            0.358   0.003   0.016\n",
    "#   1 dense_2/W_0           21.989   0.002   0.061\n",
    "#   1 dense_2/W_1            0.273   0.010   0.014\n",
    "#   1 dense_3/W_0            5.282  -0.008   0.104\n",
    "#   1 dense_3/W_1            0.040  -0.002   0.013\n",
    "\n",
    "# Train on 54000 samples, validate on 6000 samples\n",
    "# Epoch 1/2\n",
    "# 54000/54000 [==============================] - 3s - loss: 0.0796 - acc: 0.9753 - val_loss: 0.0658 - val_acc: 0.9820\n",
    "# Epoch 2/2\n",
    "# 54000/54000 [==============================] - 3s - loss: 0.0607 - acc: 0.9803 - val_loss: 0.0745 - val_acc: 0.9803\n",
    "#   0 dense_1/W_0           32.546  -0.004   0.051\n",
    "#   0 dense_1/W_1            0.430   0.002   0.019\n",
    "#   0 dense_2/W_0           23.191   0.001   0.064\n",
    "#   0 dense_2/W_1            0.338   0.011   0.018\n",
    "#   0 dense_3/W_0            5.535  -0.009   0.109\n",
    "#   0 dense_3/W_1            0.060  -0.003   0.019\n",
    "#   1 dense_1/W_0           34.445  -0.004   0.054\n",
    "#   1 dense_1/W_1            0.490   0.001   0.022\n",
    "#   1 dense_2/W_0           24.277   0.001   0.067\n",
    "#   1 dense_2/W_1            0.420   0.012   0.023\n",
    "#   1 dense_3/W_0            5.758  -0.011   0.113\n",
    "#   1 dense_3/W_1            0.081  -0.004   0.025\n",
    "\n",
    "# Train on 54000 samples, validate on 6000 samples\n",
    "# Epoch 1/2\n",
    "# 54000/54000 [==============================] - 3s - loss: 0.0473 - acc: 0.9854 - val_loss: 0.0686 - val_acc: 0.9807\n",
    "# Epoch 2/2\n",
    "# 54000/54000 [==============================] - 3s - loss: 0.0414 - acc: 0.9864 - val_loss: 0.0668 - val_acc: 0.9808\n",
    "#   0 dense_1/W_0           36.141  -0.005   0.057\n",
    "#   0 dense_1/W_1            0.551   0.000   0.024\n",
    "#   0 dense_2/W_0           25.319   0.001   0.070\n",
    "#   0 dense_2/W_1            0.497   0.014   0.028\n",
    "#   0 dense_3/W_0            5.970  -0.012   0.117\n",
    "#   0 dense_3/W_1            0.098  -0.004   0.031\n",
    "#   1 dense_1/W_0           37.838  -0.005   0.060\n",
    "#   1 dense_1/W_1            0.600  -0.001   0.026\n",
    "#   1 dense_2/W_0           26.329   0.000   0.073\n",
    "#   1 dense_2/W_1            0.567   0.014   0.033\n",
    "#   1 dense_3/W_0            6.136  -0.014   0.121\n",
    "#   1 dense_3/W_1            0.117  -0.005   0.037\n",
    "\n",
    "# Train on 54000 samples, validate on 6000 samples\n",
    "# Epoch 1/2\n",
    "# 54000/54000 [==============================] - 3s - loss: 0.0354 - acc: 0.9876 - val_loss: 0.0619 - val_acc: 0.9837\n",
    "# Epoch 2/2\n",
    "# 54000/54000 [==============================] - 3s - loss: 0.0336 - acc: 0.9890 - val_loss: 0.0634 - val_acc: 0.9840\n",
    "#   0 dense_1/W_0           39.366  -0.005   0.062\n",
    "#   0 dense_1/W_1            0.638  -0.002   0.028\n",
    "#   0 dense_2/W_0           27.335  -0.000   0.076\n",
    "#   0 dense_2/W_1            0.643   0.014   0.038\n",
    "#   0 dense_3/W_0            6.311  -0.015   0.124\n",
    "#   0 dense_3/W_1            0.135  -0.005   0.043\n",
    "#   1 dense_1/W_0           40.956  -0.006   0.064\n",
    "#   1 dense_1/W_1            0.702  -0.003   0.031\n",
    "#   1 dense_2/W_0           28.255  -0.001   0.078\n",
    "#   1 dense_2/W_1            0.713   0.015   0.042\n",
    "#   1 dense_3/W_0            6.442  -0.016   0.126\n",
    "#   1 dense_3/W_1            0.150  -0.006   0.047\n",
    "\n",
    "# Train on 54000 samples, validate on 6000 samples\n",
    "# Epoch 1/2\n",
    "# 54000/54000 [==============================] - 3s - loss: 0.0280 - acc: 0.9906 - val_loss: 0.0732 - val_acc: 0.9818\n",
    "# Epoch 2/2\n",
    "# 54000/54000 [==============================] - 3s - loss: 0.0265 - acc: 0.9909 - val_loss: 0.0727 - val_acc: 0.9812\n",
    "#   0 dense_1/W_0           42.340  -0.006   0.067\n",
    "#   0 dense_1/W_1            0.733  -0.005   0.032\n",
    "#   0 dense_2/W_0           29.111  -0.001   0.080\n",
    "#   0 dense_2/W_1            0.776   0.015   0.046\n",
    "#   0 dense_3/W_0            6.574  -0.017   0.129\n",
    "#   0 dense_3/W_1            0.161  -0.006   0.051\n",
    "#   1 dense_1/W_0           43.770  -0.007   0.069\n",
    "#   1 dense_1/W_1            0.781  -0.005   0.034\n",
    "#   1 dense_2/W_0           30.020  -0.002   0.083\n",
    "#   1 dense_2/W_1            0.874   0.016   0.052\n",
    "#   1 dense_3/W_0            6.704  -0.018   0.131\n",
    "#   1 dense_3/W_1            0.189  -0.007   0.059"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Intermediate Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_1 (18.307556, 0.16563581, 0.47472247)\n",
      "out_3 (42.404495, 0.64846009, 1.242806)\n",
      "out_4 (1.4240878, 0.1, 0.29720506)\n"
     ]
    }
   ],
   "source": [
    "def get_outputs(inputs, model):\n",
    "    layer_01_fn = K.function([model.layers[0].input, K.learning_phase()], \n",
    "                             [model.layers[1].output]) \n",
    "    layer_23_fn = K.function([model.layers[2].input, K.learning_phase()],\n",
    "                             [model.layers[3].output])\n",
    "    layer_44_fn = K.function([model.layers[4].input, K.learning_phase()],\n",
    "                             [model.layers[4].output])\n",
    "    layer_1_out = layer_01_fn([inputs, 1])[0]\n",
    "    layer_3_out = layer_23_fn([layer_1_out, 1])[0]\n",
    "    layer_4_out = layer_44_fn([layer_3_out, 1])[0]\n",
    "    return layer_1_out, layer_3_out, layer_4_out\n",
    "\n",
    "out_1, out_3, out_4 = get_outputs(Xtest[0:10], model)\n",
    "print(\"out_1\", calc_stats(out_1))\n",
    "print(\"out_3\", calc_stats(out_3))\n",
    "print(\"out_4\", calc_stats(out_4))\n",
    "\n",
    "# out_1 (15.320195, 0.15846619, 0.36553052)\n",
    "# out_3 (31.983685, 0.52617866, 0.82984859)\n",
    "# out_4 (1.4138139, 0.1, 0.29160777)\n",
    "\n",
    "# out_1 (15.458527, 0.15253167, 0.38208964)\n",
    "# out_3 (33.913242, 0.54224658, 0.90698332)\n",
    "# out_4 (1.4142052, 0.1, 0.28973988)\n",
    "\n",
    "# out_1 (16.639494, 0.15411146, 0.41647691)\n",
    "# out_3 (35.837318, 0.58614647, 0.99438524)\n",
    "# out_4 (1.4156684, 0.1, 0.29898632)\n",
    "\n",
    "# out_1 (16.877953, 0.15098023, 0.43457347)\n",
    "# out_3 (36.548904, 0.59088105, 1.0605338)\n",
    "# out_4 (1.414073, 0.1, 0.29486296)\n",
    "\n",
    "# out_1 (18.307556, 0.16563581, 0.47472247)\n",
    "# out_3 (42.404495, 0.64846009, 1.242806)\n",
    "# out_4 (1.4240878, 0.1, 0.29720506)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Intermediate Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_0 (4.5891175, -7.2404553e-05, 0.0072430321)\n",
      "grad_1 (0.44867462, -0.00047407666, 0.019823136)\n",
      "grad_2 (2.6217206, 2.5737674e-05, 0.0072415713)\n",
      "grad_3 (0.18206903, 0.00012690801, 0.011378606)\n",
      "grad_4 (3.2452161, -2.9717739e-11, 0.064140067)\n",
      "grad_5 (0.12291637, -3.783498e-10, 0.038869571)\n"
     ]
    }
   ],
   "source": [
    "def get_gradients(inputs, labels, model):\n",
    "    opt = model.optimizer\n",
    "    loss = model.total_loss\n",
    "    weights = model.weights\n",
    "    grads = opt.get_gradients(loss, weights)\n",
    "    grad_fn = K.function(inputs=[model.inputs[0], \n",
    "                                 model.sample_weights[0],\n",
    "                                 model.targets[0],\n",
    "                                 K.learning_phase()], \n",
    "                         outputs=grads)\n",
    "    grad_values = grad_fn([inputs, np.ones(len(inputs)), labels, 1])\n",
    "    return grad_values\n",
    "\n",
    "gradients = get_gradients(Xtest[0:10], Ytest[0:10], model)\n",
    "for i in range(len(gradients)):\n",
    "    print(\"grad_{:d}\".format(i), calc_stats(gradients[i]))\n",
    "\n",
    "# grad_0 (1.7725379, 1.1711028e-05, 0.0028093776)\n",
    "# grad_1 (0.17403033, 3.4195516e-05, 0.0076910509)\n",
    "# grad_2 (1.2508092, -7.3888972e-05, 0.003460743)\n",
    "# grad_3 (0.12154519, -0.00047613602, 0.0075816377)\n",
    "# grad_4 (1.5319482, 4.8748915e-11, 0.030318365)\n",
    "# grad_5 (0.10286356, -4.6566129e-11, 0.032528315)\n",
    "\n",
    "# grad_0 (3.4017127, 8.7506611e-05, 0.0053710202)\n",
    "# grad_1 (0.33252886, 0.00055375684, 0.014685402)\n",
    "# grad_2 (1.9467239, -3.3674216e-05, 0.0053783408)\n",
    "# grad_3 (0.16811177, -0.00019758131, 0.010505128)\n",
    "# grad_4 (1.8920149, -3.4779077e-10, 0.037405979)\n",
    "# grad_5 (0.11266962, -2.7939678e-10, 0.035629261)\n",
    "\n",
    "# grad_0 (4.4856653, 0.00014608752, 0.0070793224)\n",
    "# grad_1 (0.43840903, 0.00093970483, 0.019352324)\n",
    "# grad_2 (2.4390073, 9.5780408e-05, 0.006736787)\n",
    "# grad_3 (0.19859995, 0.00049467472, 0.012402636)\n",
    "# grad_4 (2.9728518, -1.4736087e-10, 0.058762152)\n",
    "# grad_5 (0.13749355, -6.9849196e-11, 0.043479279)\n",
    "\n",
    "# grad_0 (0.94408065, 5.3343301e-06, 0.0014902415)\n",
    "# grad_1 (0.092352077, 3.1091229e-05, 0.0040813056)\n",
    "# grad_2 (0.57179779, -2.3590032e-05, 0.0015793034)\n",
    "# grad_3 (0.043331128, -0.00013161075, 0.0027049957)\n",
    "# grad_4 (0.63560385, 1.2043984e-10, 0.012562943)\n",
    "# grad_5 (0.028290441, -1.7062121e-10, 0.0089462232)\n",
    "\n",
    "# grad_0 (4.5891175, -7.2404553e-05, 0.0072430321)\n",
    "# grad_1 (0.44867462, -0.00047407666, 0.019823136)\n",
    "# grad_2 (2.6217206, 2.5737674e-05, 0.0072415713)\n",
    "# grad_3 (0.18206903, 0.00012690801, 0.011378606)\n",
    "# grad_4 (3.2452161, -2.9717739e-11, 0.064140067)\n",
    "# grad_5 (0.12291637, -3.783498e-10, 0.038869571)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
